{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "u3BBz0BfjQDe",
        "V4a4gCyytCMN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadic-ifrn/multicore_programming/blob/main/notes/Treinamento_IIII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Benef√≠cios do Uso de GPUs  \n",
        "---\n",
        "\n",
        "A Unidade de Processamento Gr√°fico (GPU) fornece muito mais instru√ß√µes por segundo e largura de banda de mem√≥ria do que a CPU dentro de uma faixa de pre√ßo e consumo de energia similar.\n",
        "\n",
        "**Diferen√ßa de Capacidades entre GPU e CPU** üß†üí°:\n",
        "\n",
        "- A CPU √© projetada para executar uma sequ√™ncia de opera√ß√µes da forma mais r√°pida poss√≠vel e pode executar algumas dezenas dessas threads em paralelo.\n",
        "- A GPU √© projetada para se destacar na execu√ß√£o de milhares delas em paralelo.\n",
        "\n",
        "<center>\n",
        "A GPU dedica mais transistores ao processamento de dados\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/7kCTLne.png\" alt=\"smit\" width=500 heigh=100>\n",
        "        <figcaption>Fonte: https://docs.nvidia.com/cuda/cuda-c-programming-guide </figcaption>\n",
        "</figure>\n",
        "</center>\n",
        "\n",
        "**Combina√ß√£o: CPUs e GPUs** ü§ùüöÄ:\n",
        "- A GPU pode ocultar lat√™ncias de acesso √† mem√≥ria com c√°lculos, em vez de depender de grandes caches de dados e controle de fluxo complexo.\n",
        "- Em geral, uma aplica√ß√£o tem uma mistura de partes paralelas e partes sequenciais, ent√£o os sistemas s√£o projetados com uma mistura de GPUs e CPUs para maximizar o desempenho geral. \n",
        "- Aplica√ß√µes com alto grau de paralelismo podem explorar essa natureza massivamente paralela da GPU para alcan√ßar um desempenho superior ao da CPU.\n",
        "\n",
        "***CUDA: Uma Plataforma e Modelo de Programa√ß√£o Paralela de Prop√≥sito Geral***\n",
        "\n",
        "Em novembro de 2006, a NVIDIA¬Æ introduziu o CUDA¬Æ, uma plataforma de computa√ß√£o paralela de prop√≥sito geral e um modelo de programa√ß√£o que aproveita o motor de computa√ß√£o paralela nas GPUs da NVIDIA.\n",
        "\n",
        "\n",
        "<center>\n",
        "O CUDA √© projetado para suportar v√°rias linguagens e interfaces de programa√ß√£o de aplicativos.\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/Q6BMtex.png\" alt=\"smit\" width=500 heigh=100>\n",
        "        <figcaption>Fonte: https://docs.nvidia.com/cuda/cuda-c-programming-guide </figcaption>\n",
        "</figure>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "cpBoErUNEGWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Get Started\n",
        "---"
      ],
      "metadata": {
        "id": "_1zClqsObILM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 1:** Ir para https://colab.research.google.com no navegador  e clicar em Novo Caderno.\n",
        "\n",
        "![WhatsApp-Image-2020-06-08-at-7.05.14-PM.jpeg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "dr0l8M2SdRjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 2:** Precisamos mudar o tempo de execu√ß√£o da CPU para a GPU. Clique em `Runtime > Alterar tipo de tempo de execu√ß√£o > Acelerador de hardware > GPU > Salvar`.\n",
        "![WhatsApp-Image-2020-06-08-at-7.05.40-PM.jpeg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAIvA0IDASIAAhEBAxEB/8QAHAABAAIDAQEBAAAAAAAAAAAAAAMEAgUGAQcI/8QARxAAAQMCAgUHBwwCAgEDBQAAAAECAwQRBRITFCExUwYVQVFhkdEiMlKSk6HiMzRDVXFyc4GjscHwI/EWQmIHJCU1RWOy4f/EABcBAQEBAQAAAAAAAAAAAAAAAAABAgX/xAAnEQEAAgICAQQBBAMAAAAAAAAAAREhQTFhAwISUfBxBAWBwZGh4f/aAAwDAQACEQMRAD8A+izcsap8CtZTsZKqWz3VUT7EPeSuEyzVqYhOipG26sVd73L0/Zv/ADOnbgmGsfnbRw5u1l/cX0bZtksn2HF8X7d5vX5vT5f1Pr93t4h0vJ+t8Xp8c+Pwej2+7mWYPEC7EU7PDmgPn/JPGXYrT0lRU8tFnrnNe+XDmarfZfZlRmdLIl95aoeVCsqKWoqK2V+Grgra1yywsa9z1eiZlRqecqLbKmy6gduDTYXj0eJVM1I+jq6Kqia2RYKprUcrHXs5MrlRUuipvultqIbkoA4/lbi0lBjOD0zsfTBaSpSdZqhdCl1ajVal5Wqib1J4segoKakghq6zlFPVI+WOSlbC5yxtVEc5VZkZlRVROtV2bRA6hQhwGH8ra1cCo6t61VVWyUVXUJA2GJrX6OVGorrq1UVqKmxLXS/TY6rk/iE+K4DQ19RTup5Z4WvdG7LvVN6Wc7Yu9Nt7Lt2gbYA46XlFU4SnKdle/SyYfapprtRM8Ujf8bdibbPRzb79xJlYi3Yg5Kixx+GRVLMYrZ6ippKWlWdqQsRHSyZktHlsqq52yypbdbpLcPKukfKynno62lqVqY6Z8M7Go6NXtVWOVUcqZVyqiKirt2FrNM3i3RA56l5XYbW5Ep2zvc/EHYejUal9I1Fcrt/mZUVb9XQdCO16AaHlbX1WGcmauso5dFURrHlflR1rvai7FRU3KpWqOWdHTVlVC+gxBY6SoZTVFU2NqxROcjVRVXNdU8tNyKqdKIIzg1bpwaD/AJTTLir6JlFXSRx1CUslUyJFhZKqIuVdubpTbltt3mDOVdHJXsgSnrEp5J3U8VasaaB8rb3Yi3zb2ql7WVU2KB0Ri92VqqcXVcuaiTA6PFMMwPEHw1NVDE1Z2xNzNe9EWyaRFut7Iq7L9m066RVdT5larVVLq1bXTs2Ch5HppI2P0jEzNRbZF8TLJPxWeovieRuVtCxyb0jRU7jhMJxXG4MP5NYlU41JWrisscUtJNBE2yOaqq5isa1fJtfbfYSOTVu9yT8VnqL4jJPxWeoviain5T0VTTYVUMiqEbib3RworW3arWucubbs2MXdfoKNBy2psRSmdDheKNSshfLSLLExqTq1Lqxt37HW9KyLbYpR0uSfis9RfEZJ+Kz1F8TkcE5VVGI0eCVNdFU0s1W2dywsjjWOVGNve+Zzmp1bbqqLfYS0/LqmqUo9Hg2LqtdFpaNqwM/zoiIqonl2SyLfysqdSqN0OpyT8VnqL4jLPxWezXxNEnK6kmoqOampK6pnqlkRtHHG3TN0a5ZMyOcjUyrsXbvVLXNrhmIQYrh8NdTK7RSotke3K5qotlRU6FRUVF+wCxTyLLC1y71RL2JirQ/N2/YcpicGNR8q6Chh5TV8VPWx1EqsSnpl0eTJla1ViVbeUu+67EG6Hag5peVlJTVC07oq6WCGZtJNiOiboWzbEs5UVF3qiKqNyoq2uhlNyuooK2WLVqx1NFOlNLWtjTQRyqqJlVb5t6oiqjVRF3qOeB0QOQoeVMkNNMlVHU11VLilVS0sFOxmdzY3O2bVa2yNTeq950eH10eJ0EdXHHNG2S/+OZise1UWyoqLuVFRSVizdLoByVPysoKTlBjlFi+NUNNq9RG2miqZ44lRixMctr2VUzKu3aUdaDjME5WyScnMLmniqcTxCrjklSOkYzM5jXqiv2q1qInkpv232XMZ+WUUOILXI+aTCUwrXNEyJM6u0qM3LZbputcm6Hag02G47HXV81DJRVdFVxsbLoqlrUV8aqqI5qtc5LXS1r3TpRDclAGsxipmpaWB8D8jnVUMarZFu1z0RU29ilirq9Via/QTTucqNbHE27lX87In2qqIBbBp0x6ndDG6OnqXzSSuhSnRrdIj2pdyLdbbE7SNcalfiWHwQ0U+gqmvV7ntRrmq3ZayuRUt07Oq1wN4DXV2Jsop44dXqJ5pGuekcLUVcrbXXaqJ0p2kdRjccMLJWUtZNGsWmc6OK2RnWuZU29iXXsA2oNS/HKaOKpkyyOSBI1siJeRH2yq3btve2221AuOQJU6LQ1GiSVIFnRqaNJF2Zb3vv2Xta/SOjttgc5WY4589NFSRVDY3VjYHVGRujel1RzUW9+jfZN2xTa1lfqmjalLUVD33s2FqLZE3qqqqIneNWbpeBomY4+oxOgipqaV9LVQvk0io1FRUVE6XXS11vs6rX2k+LPnhySLiMVBStaukmdlzK7/qiZkVLb+0DbA0LcXqY+T6Vk9M/TpSunV2WzLpuRdt0Vdi2FNUVdHXsgra7Txy0zp1e5jWaNWql7WRPJs7p27N43Q3wNBg2I1dfiddp/Jp8kUlPFlRFax2bavTdbIvZcwkdXVGJ4m1mKyUsVNkyNSONWpdl1Vyq2/vE4HQg5ODH62TFcLdJZlJVUrFlYjU8mR6qjXX32uiJ+ZchxOpqOV76Rr01KOFzcuVPKkarVVb79mdEFffwOhAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADxdqKh6ANByfwSTCOTVNh8+hdUxRuY58e1FVVVd6oi9JzzuQlXU4VDQVE9MiNwaOgcqXemla9HotlRLs8nsXsPoAJuxzXJnAnYTLPLJhGC4e+RrWImGsW77XurnK1uzdZttnWp0oBbHN4/heJ1GM4TiOGw0U60aTI+KrmdGjs6NRFRWsdut1EDsPx7nGlxiOnwxlayF9LLTazIsSxq5HI5r9HfMipuy2W+86sAcPh3JCvpqehiqZ6ZVioaylldGrl8qaRHIrUVNyIi3v7zosApqyhwGho61sDainhbCqwPVzFypZFRVRF2ol7W2dptVCAnLw5XlByWlxrlDhOIRzMjghciVsTr3nY1ySRomzoe3ptsVTrATcSacbjnJCbGajGHufTZKttK6BsrVe1Xwuc60jbbWrdE2LuuQpySqF5PYjTU9BguFV0yxyU2oNdlbJGuZrnuyoq+Um7LsS+87cDUwXm3IYZyPfhnKOirGTsWjpqJsaxbczqhEyaTdbay6HXgGpm0iGm5TYZPjOAVFBTOjbLKrLLIqo3Y9rlvZF6ENXW8ma2pw3lDTMkgR+JVrKiFVc6zWo2JFR2zYv+Nd1+g60GY5tenG1XJrE5+Uja6JaCFutMlWshc+OodElrxPYiZZEVLpmcu5d2wgwrkSuF4mipheBywsqHzMr3xKtVZyq5G2y2zIq2zZtybjugKxROXILyaxCPkPhmFRyUq19A6nkTM5yRPdE9HWzWuiLbfb8jp35lp/LREfbykat0RSciqPknFsYxNV1Exqb1jRPccZg3IVuBx4HVUMFBFidKzQ1z2Ns2ojclnrfLdXIqIqKqdaLvO1p76rD9xP2JdvWDVOHw/k1jlNPgtNM/D1w/Cp5XskY9+lla5kjW3arbNVM6XS636+hbmH8mq2kpeS0T5YXOwlr0nVrl8q8Ss8nZt2r02Os29Y29YJcTh/JfE6aHCIZ5KNG4alTGjmPcqyMkbZi2VuxbrtTuVS9h3J2spU5L53wrzVSvhnyuXynLG1vk7NqXRd9jqNvWNvWQfP5+Qs720tTJS4XXzQT1blpq1FWJ8c0qvRUdlVWvTZ/1Xeqdp12D0PN2FU9IkFJArEW8VJHo4mqqqqo1Pz/AD37DZWXrFl6yxiKJzNq1D83b9hr6vDJ6jlPheJMcxIaSGeN7VVcyq/Ja2y3/Vb7S9TJNDE1roHKqJ0K3xJtLLwH97fEdjkajkxikkNXhUc1JzPV1i1T5XOdp2Nc9JHRo22VbuvZ2ZLIu5RUcmMUkhq8JjmpOZ6usWqfK5ztOxrnpI6NG2yrd17OzJZF3KdbpZOA/vb4jSycB/e3xEYJy5GbktiGoywaDDKxH4jUVawVSuRqte5VaqSI1XMel+hF6dpvuT9DWYZg1PS1tRrFQzNmfmc6yK5VRqOdtVGoqJddq2NhpZeA/vb4jSy8B/e3xEYiic5Tmjw3CH0uLY1VzpE9ldUMliRNqtRImsVFunW1d1zbaWXgP72+I0svAf3t8QOC/wCB1EdHhLpKTCcRqKOCWnlp61HLE5rpM6Oa7Iqo5Pu7bqRcp+T8+H8n62rayhhijwlKXRUzFYxsizI/yW+j+dz6DpZOA/vb4jSycB/e3xA0mF4Zij+UEuL4stIx6UyUsMVK9z0y5sznOVyJtVbbLbLb1OiIdLLwH97fEaWXgP72+IGr5Rq9aCJsTXOlbPHK1Eikei5HI6y5GuVN3UaqurqrEaaNs1G5qxyo9YdWqnRzNsqKjl0KW2qi7l3HU6WXgP72+I0svAf3t8QOMij0VA6nWia9HVL5lp+bqlsaIqJbK5I7tVF6kLMEssK4Y9yVcz6ZZGyZ6Kp8x/Q1VjVVyoiJt3nVaWXgP72+I0svAf3t8QObxiqZXSRLFSSzI1FTLNQ1LHNVdzmvbGqp9hr6yKSoijZIyStXVEgV9XQVK6N+272po1uq36bLsTadppZeA/vb4jSy8B/e3xJQ5RWwrVYXKqViMp4mMqGJh9R/kViXZb/H0OupHFDSwYnJMmHNmjfULOk8uGVCzMut1RE0e3buW+zqOv0svAf3t8RpZeA/vb4lvNmqcjnmY2mpWRzLS09YlQ160VTnVuZXZcujtdL777ews4xUMrpqaWOmlnjjRyPp6qgqMiqtrOska3VLLsVOnoOl0svAf3t8RpZeA/vb4gclh7loOa1SOdy0rJY5USgqWple5Fu3/H0W3L3mwrsWmdMx1LFPJHlVskM9BUNRV6HI5I1Xr2G90svAf3t8RpZeA/vb4gc1FJEzBkwqRtWsK0743yJQVGZHLusmTzUuvT0IQo9tdIq4tFUqxtOtOjaejqvLuqKrlXRoqXypsS/TtOr0svAf3t8TzTOu1r4ntzLZFVU/hQOboNUosXqaxvOrmSRMYxslPVvW6XvfM3bvS3Vt3HjY8KnxesrK3D5p0lVixZ8MncrURtl3x9Z1gA5LEHQVtVUSNZWMa+kSGNeb6i7JGuzNX5Pci2MsJjSOvoXLrDpGwStme+jmYjpHuRyrdzES2xd6p0HVgQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoY1VRDSxaad6MjzNZmVOlzkaifmqohOBFq8HBj9VBq8HBj9VDVYhi9RDiTMOw+hSsqli0z0fNomRsvZFV1lW6reyInQplTY5SuwtK2tczDkbI6KRKqRrEY9qqipmXYu7YvSgGz1eDgx+qg1eDgx+qhXnxOgpqZlTUVtNDTyWySySta1191lVbKU6DlBSVGDpidXNBRwLLJGj5ZURq5Xuai5lsm3LcDaavBwY/VQavBwY/VQ9jkZNG2SN7Xscl2uat0VOtFJAItXg4MfqoNXg4MfqoSkFPUw1LHvhej2skdG5U6HNVUcn5KigZavBwY/VQavBwY/VQirZKyOmV1FTw1E90tHLMsTVTp8pGu/Y1GCY5iGJRyVNXh1JR0cb5WOlStV6o5jlauxY2pa6LtuBvNXg4MfqoNXg4MfqoVocVw+pijmgr6WWKSTRMeyZrmuf6KKi7V7ClV8p8HosRpqKWvp9PUSrCjUmZ5DkRV8rbdOr7VRANtq8HBj9VBq8HBj9VCUARavBwY/VQavBwY/VQlAEWrwcGP1UGrwcGP1UJQBFq8HBj9VCKop4EiX/AAx+qhaIaj5JwHtP81i+4n7EpFT/ADWL7ifsSgADWYzi0eDYfrckE06LLHE2KHLnc57ka1EzKib1TeqAbMGkouUVNU1U1LVQzYdUxLHmhq1YirnVUZlVrnNW6oqWRb3QuT4th1JnWpxCkhSN+jeskzW5XZc2VbrsXLtt1bQL4K9NV09ZTMqaWoingel2SxPRzXJ1oqbFNVXcpsPiwmpr6Copq9Kd7I5GQVDXZVc9G2VUvZdt/wAh0N6DWYXifOb69qQrHqlW6m86+fKjVzbtnnbuw2YAAAAAAAAAAAAAAAAAAAAAAAKldXQ4fTLPLmVMyMaxjbue5VsjUTpVVAtg0knKWipY5n17ZaKSLKroqhWo5UctkVLOVF3LuXoUzxDH6Gjo5pYqinnmjYkiQNmTM5Fst+lbWVF3AbgEC1MKVTKZz0SZ7HPazraioir707zXxYy6eqmjgwytkjhmWF86LEjEVN67Xo6yX6gNuVK1qOZEjkRU0ibFTsUp0eO09bURxMgnjbO1zqeWRqIyZE3q2yqvbtRLoXqvzYvxP4UDNtPBb5GP1UPdXg4MfqoSN81D0CLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qg1eDgx+qhKAItXg4MfqoNXg4MfqoSgCLV4ODH6qDV4ODH6qEoAi1eDgx+qgJQAAAHM8psOr6ukV9NiFVlWeC1MyGNyJaVl3Xyq7Z52+2zqN1Q09RTQuZUVslY9XXR8jGNVEsmyzURP9lwAczWPlwjlPJiT6SqnpKqlZCrqaF0ro3sc5Uu1t1sqO326NpVmmrX4nhuM4jhU607GVEbYIolkkhVzm5HuYl1urWqi2va52AEDgaCimw6ow2trcNqHUKLV6OnZAsrqbSSI5l2NRVTyUVNibL2KUGHVsFJg9Q6DEaSlidWNWOno2ySQq+VVYqxuY7YrUVLomy/Up9LAGo5O0jaDAaanalSjGoqolS1rZERXKu1G7E37uhDbgCRUraeoqafJT1ktI+988bGOW3VZyKho+TeHYhSpNJUYhVKxKyoVYJIY2pIiyOs++VF2+dsW3VsOnAA4abDK+bkTV08cE7ZecJJnRI1M740qFcuVHJZbt2oipZfzO5AHAuw9ZsKxJaeHFqqqr3wxRvq6VsGSRPNks1jVajN6uVNuVERVJKOmqKKm5PpJQVSPoa6SOrcyJz1e5zHppd13Nc5yLm6L7dx3QAAAAAAAAAENR8k4mIaj5JwHtP81i+4n7EpFT/NYvuJ+xKANByswyfFsGZSU8b3qtXTvejJdG5GNla5yo66KioiKuxb9W034A4Go5NV1BLXJSUstYzXaWthllqc80jWOTNCr5HX8myq3MtvKtczpsGxOtxhlbVYW6CF2M64scskblbGlLo0cuVypfOibEv3bTugIwTlzOH4XXUmA4xTJTQ6eaoq5KeKVUWN6Pc5WZrdC32p2nM/8AHseqtcfJR1LdJSU0DGzvpmqjo5kcqNSKyI1Eva6qv7H0wE3Eo0mA0VTRS4u6ojyJUYhJNFtRczFaxEXZu3LvN30ABd29ABQAAAAAAAAAAAAAAAAAAA1WN0s1VTQyU7UfLTzsnSNVtnyrtbfoWyrbtNqAOdxBmKYnhddFqGharWaGGRzVke5HXW6o5WolkRE2/bYgq8MrKqmx17KRWy1uiWJrnNzLZjUVFVFsllRek6kAaCo5PNmx+Gv09UjEjej2pWSouZVaqZURbI3Yt02Ju2HuGYNoqysqqjWGSPrJJI2tqXoxzVtZVYjsq/mhvgIwOZosGnhxmnczWo6GhSRIWTyMciq5LIjEbtyol/OW+5De1fmxfifwpZK1X5sX4n8KBYb5qHp43zUPQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4EdQ6fRO/xx+0XwLRDUfJOA9p/msX3E/YlIqf5rF9xP2JQPADluX0Wm5Mti1eKfPW0rdDMtmSXmZ5Lti7F3LsX7FIOpB80oZajBq2vdBBSYQqYhRU0tBSLmhbG522VFVrU8tHWujU8zrNlPjOJ1eMPoqXElgjfjOppJHFG9WRpS6RWpdFS+a63W/dsLzwOzlmjp4XzTSNjjY1XPe9bI1E3qqruQzY5sjUexyOaqXRUW6KhyC1tTV8g+UDKydZ5qZtZTaZWo1ZEZmRFVGoiXta9kRDUz49iuA4f/gr+ckdhbKlmaONNXdnYxFTLlRWWeq+Uv/RfKtciPoc88VNC6aeVkUTEzPe9yNa1OtVXcIJ4qmFs0ErJYntRzHscjmuRdyoqb0PnWKvxmtwKspMQnr4YmVdEsUk+qLM9HytRzXNizNyotnItkvuW6It79fjGKUzcYq48TViYTPFBHROijXWUVrFu9cubM9XKjcuVEtuUsK7tQh8+rMcxqno8TrG1k8v/AMqlBDCyKFNAxXN8pFdZFdtVEzOy7Uvc6HkzU4nPT1ceKMmR0NRkidUOh0rmZWr5aQuViORVXdbZZbCMxZOJp0IAAAAAAAAAAAAAAAAAAAGk5SO/9jTMc9WU8lXHHUORbf41Xair0Iq2RftA3ZFLLFBE6WaRkcbdrnvciIn2qpyeN0lFRUOIRYZVPo5GpC+WCmRqRtRX2RbZVRFXptZVsn544w+slpMejlrZZIKVsbGRqxiZlVrVVXKjb3vt2WQDsgc5U1mMM5UU0EdLTrA6CVUatU5EeiOZ5Spk2Kl923eu0p4VhyTYvX1DsJw2ZrcQkXWpXf5mWtuTRru6PKQkEuwKldmRkWVEVdImxVt0KcjgLFZieGVOjiY2qSfLUMfeWp6U0qdFkTrdZdmzcdhV+bF+J/ClGbXT2+Tj9ovgLz8OP2i+BK3zUPQIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4C8/Dj9ovgTACG8/Dj9ovgLz8OP2i+BMAIbz8OP2i+AvPw4/aL4EwAhvPw4/aL4AmAAAxVbAe3PLoVZ6psSom1VXqIdeTqUDYXQXQ1+vf+KjXv8AxUDYXQXQ1+vf+KkkU7pr5UtbrAuXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdCKoVNE4wvJ2d5FULJonbu8C1T/NYvuJ+xKRU/zWL7ifsSgCvUU8VSxI54Y5WI5r0a9qORHIt0Xb0oqIqFgAUqjDaKrdK6poqeZZo0il0kbXZ2It0at02pdVWymFPhGG0aMbS4dSQNjfpGJFA1qNfly5ksmxcuy/VsNgAKqUVLoJoEpoUimVyyM0aZXq7zsydN+m+8ipsHwyiSZtJhtJTpP8qkUDWaT71k2/mXwBrocGwulptWp8No4adz0kWKKBrWq5FRUdZEtdFRFv2EkuF4fUVsVdNQUslXFsjnfC1ZGfY5UuhdAFR1BRuhnhWkgWKdVdNGsaZZFXerk6VXtPaKgpMOp0p6KlhpYU2pHBGjGp+SbC0AAAAAAAAAAAAAAAAAAAAEckbJY3RyNa9jks5rkuip2oSACnFhtBDSupoaKnjp5L54mRNRjr9aIllPW0FI2F8SUsKRvREezRpZyIlkRU6bIiJ+RbAAhjgihz6KNrM7le7K1EzOXeq9akwAqRYfRU1Q+ogo6eKeTz5GRNa532qiXU9rPNi/E/hS0U8Qvo47b9In7KBZaqZUPboVmrJlTd3nt5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdBdCveTs7xeTs7wLF0F0K95OzvF5OzvAsXQXQr3k7O8Xk7O8CxdAV7ydneALSmD9xmpHJ5oGmmerqqRF6ET+TESfPJfsT+ShjWJswfBavEHtzJBGrkb6S7kTvVALFVW0tFGklXUw07F/7SyIxO9RS1tLWx6SkqYahnpRSI9O9D4DGmKcseUKRvn0tZUI9WaR1mplarsqdSbLIQQVGKcmcXzM0tJWQus5jtl+xU6UUD9GFyh+k/L+TSYLiTMYwakxBjcqTxo5W+iu5U/Jbm7ofpPy/kC2AAAAAAAAAAAAAAAAAABDUfJOJiGo+ScBZp/msX3E/YlIqf5rF9xP2JQPDRcq8XmwPA1rIJaaJ+nhiWWqaqxxtfI1quciObsRFVd6bjemsxrC+d6KOnSXRZKmGfNlzX0cjX23pvy2v2kGhwzler5546mekxKnbNTwRV2GMVInvlcrcqor3JduxVs5djk2Gxq+VdLS1L6dtJWVE7axKJI4WNVXSLFpdl3Ilsuy6229m0hruSzqieufSV2rpPPDVMYsWdsdRGqLntmS6ORrUVuzde+0wo+S1RHWsravEmzT8468/JTaNqroNDkRMy2TpvdertLGeSel6PHm1OA1GJ0tFUufAkjXUz8iSNexVRzV8rLsVF/wC1uq5oYOV9dJWUU8uG1r4ajCEq30kDYnOY7Ml35lcmy25M19u650VBgzaKgrqV86yJVTzTK5G5cqSOVbb13X3mvw3kvNSaDT17JnRYdzemWDIitvdHecu2yIip079m4meTpJNywoIWJLHBVVMDadlVPNAxFbTxPS7XPuqLuRVs1FWyXsYcrMWr6Cnw+PDY53PrapkKywpErmNVFXyUkciZltsuipvv0Gtd/wCnlMq0z82HTvZSw0szq3DWVCro25UdHmd5CqnXmTdsOkxPCUxBcPVsuiSjqW1CJkvmytcmXelvO39hZ/tI/r/aonKikSqSBaesWnSoSkWvyN0Omvly783neTfLlvsuYN5WUqrJJqVetGml0dWkbVilWNFVyN8rMnmusrkRFtsUj/4vLp9BzinNWu69quh/yaTPpMukzeZn8q2W/Rex7Tcmqmnidh/Oi80f5UbTNgRJLSZvJdIqrdqZltZqLsS6qTXa4vpPPyqoKaJkszJ2xuw92IZsiLaNMuxbL53lJs3dpinKiFlG6eow7EKeXSMijp5GMV8zn7WoxWuVjr7f+2yy3sU6TkpiMb2vqMaY9YsPWggWKjRitbdqo52Zzkcvk2VLIi9SFV/ICKagqIKiejV0lRHPHFFQI2lY9iKm2FXORcyOXNtS+zdYs9ENonK2nfooosPr5a58r4nULWs0sasRFcrlV6MsiOat0ct8yWuYYHjznci2Y3isrrNSV8jljRHWbI5ETKib7IiW6yCm5KPw9KWow+fD6OsiWW60+HJHA9r8t00bXot/IaqLmVdnSmwt0/JhrOSDsBnq3So5H3qGMRi5nPV6ORLqmxVTuGiOXq8qIYaeZ9Vh+IUssaxtZTyxtV8qyLZiMyuVqqqoqWulumxQm5ST1GJUENOk9K7TVENXTTsZna5sOdqKqK5Olq3atluT4hyYqsbwyWmxjEIal+kjkhRKNEhYrFVUzRuc7Pe9nXdZU3WMKLkcykdRyI6hp3QSTSOZQ0DaeN2dmTY1HLa2+6qqr2Em6k3Da8m6qav5M4XV1L9JPNSxSSPsiZnK1FVbJsTabYoYPh64Vg1Fh6y6XVYGQ6TLlzZURL2uttxfNTV4SLqLegAigAAGvxavfh9A6eONJJXPZFGxVsivc5Gpdeq6mwKWJUDMQoX0yvdGqq1zHt3sc1UVqp9iogGqrsTxjB6KpqKmmhrGRxo9slO3Roi3srXNc9V7bp3HuIY7I2kxKKnpqqOppqRZnSORiticrFc1F8pbrs6EVPyJJ8Hra6nqoq3EUes0OiakUSsjZtvmVquW7t3T3GTsFlmgxNstS1ZK+BsTnNjsjFRituiZl672v+YngjljNymw+kq6WknrKZssjVWRXztbolRqKmZOi9ypFjk9RjFTSpi2FU2iqUhjp5Y1dLIlmrdP8qb7qieSbl2GQyVFJUPur6VrmtsiWddERb9xUhw3EaWsqpaavpUhqJ9M5ktK5zk2IiojkkROjqG0jhhHyiikmypRVmV80lOyRWsRr5GZvJTyr7cq2VdnahHRcolqcPpZn4fOtVUK/R08WRXOa1drkVXWRN29U2k8eBqyOmZrF9DXPq75N+ZXrl3/APnv7NxSfyUa+mpY3yUs7qV0iRaxSJIzI9b2c1XbVRf+yKn2DS7XqbHoKyrgp6anqJVlhSZXo1qNjaqq3yrqi3RUVLIil6v+Tj/ET9lKmH4O2grGzMfGiJTNg0ccKRt2OV10RNieduLdf8nH+In7KBk3zUPTxvmoegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhSOTzSRTB/mgaOT55L9ifyablXhsmL8l6+ihS8skd2N63NVHIn5qhuZPncv2J/IA/PXJnFI8A5SU+IVMT3JTpJeNNjlVWOaibd21UPOUHKCt5T4mlRUNaip5EUUbfNS+7rVT7FjXIbA8cndUTwPhqHedLA7KrvtSyoq9thgvIbA8DnbUQQPmqG+bLO7MrfsSyIi9tgLfJTDZMI5L0FFMlpY48z06nOVXKn5KtjpaH6T8v5KZcofpPy/kC2AAAAAAAAAAAAAAAAAABDUfJOJiGo+ScBZp/msX3E/YlIqf5rF9xP2JQABRxPE6TB6Naute9kKOay7InSOVzlRrURrUVVVVVE2IBeBrMOxqhxZ00dK+TSw20kU0L4ZGX3KrHojkRbLZbdBswAAAAoVuJRUE9FFK2RzqyfV48qIqI7K51127rNX3F8ACvV1UFFAs9TI2KJHNbmduu5UaifmqogjqY5pZ4o8+aFyNfmY5EuqIuxVSy7FTdcCwAAAAAAAAAAABSrcSpaBGJUSOR0iqjGMjdI91t9mtRVXuAugo02JUdUyB0VQ1yTK5sabUVVbe6WXaipZbopnUVkdNU0kD2vV1TIsbFaiWRUartv5IoFsEWmi/yf5Gf4/P8pPJ2X29Ww1buUuGpBNM2WRzY4XTImiczSMal1ViuREd+SgbkED6iOKn0z82SyL5LVcu3sS69JTXF6dlXUwvbIxlMjdLO5ESNHOtZu+6rZU6LdoGzBG6VjZGsV6I998rVXatt9jXrjtClVJTJrUkkb9G/R0kr2tds2K5GqnSnSBtACGCohqYGzQSJJG7zXJuXoAmKlf8nH+In7KWypX/ACcf4ifsoGTfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWDFyXQyPFQDQ4hpYJHSRxaS/Rmt/BrFxGsT/7f+r8J1r4mv3oRapH6KAcvzjWfV/6vwjnGs+r/wBX4TqNUj9FBqkfooBy/ONZ9X/q/CTQYxWQ5v8A429//wA3wnRapH6KDVI/RQDRc/1n1X+v8I5/rPqv9f4Te6pH6KDVI/RQDRc/1n1X+v8ACOf6z6r/AF/hN7qkfooNUj9FANFz/WfVf6/wjn+s+q/1/hN7qkfooNUj9FANFz/WfVf6/wAI5/rPqv8AX+E3uqR+ig1SP0UA0XP9Z9V/r/COf6z6r/X+E3uqR+ig1SP0UA0XP9Z9V/r/AAjn+s+q/wBf4Te6pH6KDVI/RQDRc/1n1X+v8I5/rPqv9f4Te6pH6KDVI/RQDRc/1n1X+v8ACRT4/WLGv/xf6/wnRapH6KENRSR6J3koBbp/msX3E/YlIqf5rF9xP2JQPDneWVLUVuBxwU2n0q1tKueBiOexEmYquRFRU2Jt2oqbNp0QIPnVbheIUdXXyVba7EZoqyiqW1ehzOkpmPvkRsbUbmYudVRqXVFRbDm9caxfST4ZVLRS47pVbU0z2I6JKPLmc1yJ5KuS237F6j6MCxgnLk8HoZqXkvitElPVRMbUVTKaKLyHpGrnZEjzWRNi+T0bjlo8Lr2YHiNNheHSRR2plklSglplnaj/APIx0CuTO7L5zmKme9rn1UEHzahwqtibQOpGu0K4tpY448Mko4oE1eRqqkb3Oc1quVNq2S67N5r8LwXGm0NQsKyQYsmHyx1CMw2SndPKttr53SK2V10XK5qdK7k2H1gF+U+HzfE8GwmswKr5t5N1bI41ppHxS0Tmo5zZEV6ticmZz8mZFciLmRbXUmq8PldV173YfUvwl2J08k9O2nd/lgSma1LR2u5qPy3aiL5qpbZY+hgK+cUmBJWYtQMmwqXmTXal9PTTwORkcSwtREcxU8lqvRyo1yJv3HUckIJqTk3BTzxSRLFLMxjJEVFaxJXIxNvRltbssb8AAAAAAAAADRYgrqLHqXEHwzS0yU74HLFE6R0blc1UXK1FWy2VNidRvQByk9PFV4jhWIPwbRIlXJddXzPsrVyveiJdt3WXbu2KpDhuFOp4cGeyjfDOtTM6okSKzk8mRGq66dqWvs2nYgDmaPCMQpq3FJZ6uoqY5VTLE9ImtqP8aJtVG3bt2dG7pNXUx1UmHz0lHT4hNBqUzViq6Zc1OuSzWxvVqK++6yK77TugFiacVXYWtOtZFQ0UjIZKancrYo1s+RJdq9rrb+nrPcQwKGSDlDImFse99RG+JUp0Vz0RrFcrdm3bm3dNztAGYinNVeE1lTiuHVNHW1NPSsa+zGxxN0CK1EREa5l9vUt7dhXo3SUuM4hpqnFYkfWZ2xxUKvikblal1ekS77Ki2cm7oOtA3a6pxkODIjqaoWgdp34nOkznRKqrC5ZNjr/9F2dm3tKTcMmjwvDYdSSOmhfM2pikw98zVkumVyxtVquS17OS6J+30ADVG7cphGFObi1NJVxPn0FAxIppoVbldnctrKq2ciKnTexuMbnfTUCTRxaVzZEszNa/RvNmU8QYj442ruWRP2UDRtx+st/9L/X+E95/rPqv9f4TeNpI8qeSh7qkfooBouf6z6r/AF/hHP8AWfVf6/wm91SP0UGqR+igGi5/rPqv9f4Rz/WfVf6/wm91SP0UGqR+igGi5/rPqv8AX+Ec/wBZ9V/r/Cb3VI/RQapH6KAaLn+s+q/1/hHP9Z9V/r/Cb3VI/RQapH6KAaLn+s+q/wBf4Rz/AFn1X+v8JvdUj9FBqkfooBouf6z6r/X+Ec/1n1X+v8JvdUj9FBqkfooBouf6z6r/AF/hHP8AWfVf6/wm91SP0UGqR+igGi5/rPqv9f4Rz/WfVf6/wm91SP0UGqR+igGi5/rPqv8AX+Ec/wBZ9V/r/Cb3VI/RQapH6KAaLn+s+q/1/hHP9Z9V/r/Cb3VI/RQapH6KAaLn+s+q/wBf4Rz/AFn1X+v8JvdUj9FBqkfooBouf6z6r/X+Ec/1n1X+v8JvdUj9FBqkfooBouf6z6r/AF/hHP8AWfVf6/wm91SP0UGqR+igGi5/rPqv9f4Rz/WfVf6/wm91SP0UGqR+igGi5/rPqv8AX+Ec/wBZ9V/r/Cb3VI/RQapH6KAaLn+s+q/1/hHP9Z9V/r/Cb3VI/RQapH6KAaLn+s+q/wBf4Rz/AFn1X+v8JvdUj9FBqkfooBouf6z6r/X+Ec/1n1X+v8JvdUj9FBqkfooBouf6z6r/AF/hHP8AWfVf6/wm91SP0UGqR+igGi5/rPqv9f4Rz/WfVf6/wm91SP0UGqR+igGi5/rPqv8AX+Ec/wBZ9V/r/Cb3VI/RQapH6KAaLn+s+q/1/hHP9Z9V/r/Cb3VI/RQapH6KAaLn+s+q/wBf4Qb3VI/RQAWgAAFgAFhYABYWAAWFgAFhYABYWAAWFgAFhYABYWAAWFgAFiGoT/E4mIaj5JwHtP8ANYvuJ+xKRU/zWL7ifsSgADmeXEs0HJ3NA6pRzqumYqUsyxSPa6ZqK1rkc2yqiqm9N+8DpQfPcOxetoaqsWBtXFSpX0lHqmJ1C1E0T3u/yOzZ3bFa5uXynJsVew2NVyhxRcUdQ0baNj1xVKJjpo3ORrNW0uZURyXW/wBmzZs3j8H5diedJocKxmoqcDrKqsSmbPRyzwyORVjicsblTNturUW1+m3acpifKTFa3Aceo1ngZNHhqVTKhlFPAiNcrkc1Ekciu3bHottu4ER8vpQOB1qu5NYpNGs1K7DaDBnVS0lNSuiRyo5b5bvWyqvTt2bO0x/5fjmqSWpGOkfq+inlw6pp4mOklaxzF0lleqI66OaqX6kJGeEv5fQQQU6Ttp2JUPjknRqZ3xsVjVXsRVVUT81JyqAAAAAAAAAAAAAAAAAAADVcoKqakwWeWB2jkVzGJJ6GZ6NV35ItzW4lTzYVRVr6LFZWyJRyPSKpkdM5Vbtztu66dWzZdU2bLLO1iLdMDk6utxGWmrKOSSmWKPDEmlfonI56ua9LJ5Vk81Ov37MlxispX4NTQ4dVSRyMRHKzR2lTRXs270VLLvvbcWmbdUDk4UkrMcxFJabFpWtqWNa6GuWOOFNGxbK1JW9Kqq2Rd/SbCLTw8q3xuq55YpKR0qRvVMrFzoiWRETo6VuvaT4VvStV+bF+J/CnN4VPUNdglWtVUSSYg1+sMfKrmeYrkytVbNsqW2W7TpKvzYvxP4UonankoZWPG+ah6AsLAALCwACwsAAsLAALCwACwsAAsLAALCwACwsAAsLAALCwACwsAAsLAALCwACwsAAsLAALCwACwsAAsLAALCwACwsAAsLAALAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAENR8k4mIaj5JwHtP8ANYvuJ+xKRU/zWL7ifsSgCpXUNNiELYaqPSRtkZKiZlSzmORzV2dSoilsAamswDC659S+ppsz6lrGyubI5irkW7F8lUs5FXY5LL2kdHyawqiex8FM/O2oWqR755HuWVWaNXKrnKqrl2bft3m6AGviwqijo6qkSnatPVPkfNG5Vcj1eqq+9+u67ChHyRwWKKpjSmlelTBq0qy1Mr3Oi9G7nKqInRbcb8Aa6owehqq1lZNArpmQuhvnciOjdva5qLZydjkUqwcl8JghWJsEro80bkbJUyvy5HI5iNzOXKiKiLZLJ2G7AAAAAAAAAAAAAAAAAAAAAABDPBFUwPgmjbJFI1WuY5LoqL0FOHBKCnbKjYXv0keiessr5FyeiiuVVROxDZADXR4RRRxva2J6pJAlO/PK9yrGl7JdVv8A9l27yyylgY2FEib/AIEtFdLqzZbYq7d2wsACvDSw08s74mZXTv0ki3VbusiX7NiINVh1xKvJ/nSPRZ7r5t72tu3lgAa6mwehpKnWIYFbImbLeRzmszLdcrVWzb9iIWKvzYvxP4Uslar82L8T+FAsN81D08b5qHoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGo+ScTENR8k4DGnYi00S3d5if9l6iXRp1u9ZTGn+axfcT9iUDDRp1u9ZRo063espmAMNGnW71lGjTrd6ymYAw0adbvWUaNOt3rKZgDDRp1u9ZRo063espmAMNGnW71lGjTrd6ymYAw0adbvWUaNOt3rKZgDDRp1u9ZRo063espmAMNGnW71lGjTrd6ymYAw0adbvWUaNOt3rKZgDDRp1u9ZRo063espmAMNGnW71lGjTrd6ymYAw0adbvWUaNOt3rKZgDDRp1u9ZRo063espmAMNGnW71lGjTrd6ymYAw0adbvWUaNOt3rKZgDDRp1u9ZSvVNRqRKir8p0qq9ClsrVfmxfifwoFhvmoenjfNQ9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQ1HyTiYhqPknAe0/wA1i+4n7EpFT/NYvuJ+xKAI5VVGJZbeUn7khi5qOSy9dwIkkff/AK2zq3cYtkdkS63VXKl8qrayk2RvV05vzGjZa1um+/pAjbI9zkSyJsut0XrPY3udo82Xym32J9hIjGot0TosY6Nitaltjd1lAwa971REyp5N9qdoje58l7plViLax7oW5k2eSjbWRVM8jUciollRLfkBG6RyOVERVRqolsqrf8wsjke5qonkoqr2oSLG1XZlTb9oyNve226qBEkrsqqqdGzyVRL/AJmeZ7VajrLd1rp9h6kTURUtsVLbVuNE21rLvve637wMM7lkbZURMypawY57ka1tkWyqqrt6TNImJayblvv6RomWRLbt1lAj0r3JdqNTyM20mat2ovWh5kb1dGX8jJEsiIm5APQAAAAAAAAAAIbK90l3K2y2Sy2ts3kxG6Njluqfbt3gRq97VkXM1yIiW2GSK5srlVMy5E3fapmsbVVVVN6WXae5UzK7pVLAQK974G2zNcqpt6w6RXujyqqbUV3h+5OrGqiJbYi3Q80bduzeub8wPHKumYl9iov8EVX5sX4n8KTq1FVHW2puIKvzYvxP4UCw3zUPTxvmoegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIaj5JxMQ1HyTgPaf5rF9xP2JSKn+axfcT9iUAAYSPypdEut0Tf1gZgiSXa5HojVbbct957pG2vdd9rWW/cBICNJWq9Gpfal722DSssq32Il12dAEgI0kar0aiO2pe9lPVka1yoq7US67AMwYOka3ettlzF0rUS+1dqJaygSgj0rUvdem27suElY5URF39gEgMWyNctkXaZAAAAAAAAAAAAAAAAiWR13I1mbLv2gSgi0rczkW6ZURVVUU9a+8iom6yLu+3wAkBG+VGxaRGqvYePlRuSyXzKnd1gSlar82L8T+FLJWq/Ni/E/hQLDfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqPknExDUfJOA9p/msX3E/YlIqf5rF9xP2JQBHI3O1G7N6Kt/tJABAsOxUbZG3RyImzaNGuXcl73Xyl/cnAEKMeiouZFXKqKpjoXqjrql1bbzlUsADBWrpUclrWspisaqr9uxzbEoArrG9175U8lE2L2mT43K5ypbarVS/YpMAIkjdnzbPPze6x5o12Js89XEwAgjiVipfblSyLmVfcTgAAAAAAAAAAAAAAAiVr2ucrMtl27ehSUAQOicueyouZqJdetDNWI6R2ZEVqtRLL+ZIAIEhRsaNaiXuiqtrXsp5oVTpTY5MvYl7lgAebbput0ler82L8T+FLJWq/Ni/E/hQLDfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqPknExDUfJOA9p/msX3E/YlIqf5rF9xP2JQBirkal3KiJ1qZEU18qW35m/uBm1zXJdrkVOxTIrKrm57qma6XtsS3WeZlypdyWzbPKW1rdYFoFZqpna5VddWLa67zHOuV9nLbJfzr7QLYIMqJO3avmra7l2mM71a5bKqKiXTyre7pAsmKuRtrrvWyEDlW8jszvJeiIl9nQeXu5l3Lnz7W33b+gC0CFUVZ7XWyNvZF7SLOqsaiP8pI1zbemyAWwQsuj7XVUVqLtW+0wV66ZLKt81lRXdH2ATI9qrZF27fcZleH5RPsd/+xYAAAAAAAAAAAAAAAAAAAAVqvzYvxP4Uslar82L8T+FAsN81D08b5qHoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGo+ScTENR8k4D2n+axfcT9iUip/msX3E/YlAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFar82L8T+FLJWq/Ni/E/hQLDfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqPknExDUfJOA9p/msX3E/YlIqf5rF9xP2JQPDneWFfU4ZgC1FLUS08i1EEaywxJI9rXSta7K1WuutlWyWX7DojX4phsWK0zKed0jWsminRY7IuZj0em9F2XalyDRMxiXDMLdVNrKytR8yRrJjbWYeyHZe6qsLFsu7Y1238xRcsJsWgpEwrDo6iqmhkmkjfVIyNjWP0a2ejXZruRcuxEVNqqhuMXwWPFXUkq1VTSz0kiyQzU6tzNVWq1djmuRboq9BQh5H0tNFA2jxDEKaaJJW6xHIxZHtkfnc12ZqoqZlui2unQpRRXlXiFLimJyV1CyOgpaGCobEkl50e9XojVTLa6q23nWSybVvskq+VtdhzZIavCI216aB0UMdXmZI2SVI/PViWVFXalrbrKpfm5K0M0sueapWKakbRyxLJmSRjb5XK5UV2ZMy7UVN+25h/xKmlV0lXXVtVOroVSeZzM7WxPR7WJlaiWzJt2XXrG+hBUcqp6KeejqcPjbiDFpkihjqFc2bTOy7HKxFs1UdfZuS/SXsRxiqpcaoMOpqNky1Eckz5JJ9GkbGKxFWyNW6+Xu7PzSrWYO7EeWuH4hJSPZDhsMmWdz22me+yIiNRb2b5S3VE2rsubaTDYZcWp8Re5+mghkha1FTKrXq1Vult/kJ09Y1H8/8NuYw3/1DpMRqUjhjglbNDLNTx01W2adciXyviRLsVUTYl16lspkzl4yPBpsQqqekY1HxRxrFiDHx53rbLI5Uasat3uulkTcq7jcUfJqKihfTR4hiC0WjdHFS6VGsha70Va1H7Oi7lt0Ff8A4fSyaZ9TX19RVyJGjKqR7Eki0aq5mVWsRLoqrtciqvTcDUJyzrMSWg5riw6TNiWp1TmVuljX/Gr00b2sW6KnTZFRUtbbdOgxTF6ujxbDcPpKKOokq0kerpJ9G1jWZbrsa6/nf3emM3J/WKSnjnxOvmnp6lKmOpc6POj0RUtZGZESyqlkb09e0vz4bFPilJXvc9JqVkjGNRUyqj7Xvs/8UKNNDyr01FhdRqVucFnTLpfk9G17t9tt8nZa5Q/5fik2GLM3CoKeapwx+IUearV6KjUbmR9mbFTOipa6L02NhDyOpoKmCRtfXuhp3SugpnOZo4tIjkcieRmXzltdVt9mwss5M0LYqSJXzuZS0L6BiK5PKjcjUVVsnneQm1LdOwznJi2kfytr6KCKeqpGyzLh1PULBFOiMc+SVGXRysRUWyovV0dpNUcrsSpHYhrOCwo3DVY6qdHXZkyPS6LHeNFctr3Rcu7Yql13I6jkhjjmq6yVY6eKnR7nMRysjkSRt7NRL3RE3bu3aW6vk3R1rMVbNLPbE2MZNlcnko1LJl2bPzuawkdtRU8vqGnx12Hf+0WOKqZSSZq1rZ87rJdsNruYiuRFW6dNkWx2JpW4AyLEpKuCvrYI5ZUmlpY3tSKR6IiXW7Vcl7JdEciL0obozrtdvQAUAAAAAAAAAAAAAArVfmxfifwpZK1X5sX4n8KBYb5qHp43zUPQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAENR8k4mIaj5JwHtP81i+4n7EpXp2rq0XluTyE6ur7CXI7iO93gBmDDI7iO93gMjuI73eAGYMMjuI73eAyO4jvd4AZgwyO4jvd4DI7iO93gBmDDI7iO93gMjuI73eAGYMMjuI73eAyO4jvd4AZgwyu4jvd4DK7iO93gBmDDK7iO93gMruI73eAGYMMjuI73eAyO4jvd4AZgwyO4jvd4DI7iO93gBmDDI7iO93gMjuI73eAGYMMjuI73eAyO4jvd4AZgwyO4jvd4DI7iO93gBmDDI7iO93gMjuI73eAGYMMjuI73eAyO4jvd4AZgwyO4jvd4DI7iO93gBmVqvzYvxP4UmyO4jvd4FeqRUSK7lX/ACdNupQLTfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqPknExDUfJOA1bamZGNakioiIiJY91mZfpXf3/ZAnmp9h6BNrMy/Su/v+xrMy/Su/v8AshNVygrqihw+PVVa2oqKiKnY97boxXuRM1umyX2AbvWZl+ld/f8AY1mZfpXf3/ZxuONxrCsIq5OcpKuK8CxPXLHMj9K1HNuxrW5VRft33uWncpKmGOtZUUFPDVUkkbHo6sRIUa9Lo5ZHNSyb7plVb7rgdRrMy/SO/v8AsazMv0jv7/s5Gn5WzV0VElDQQzz1M00Kprf+Jro96o9GrmavQqJ+RlDyqqK1kTaLDGyT6F81QySoyJEjXqxURcq5lVzXW2ImzaqCcHLrNZmX6R39/wBjWZl+ld/f9nD1PL+mp6enkWKlY91FHWSxz1rYnI16KqNjun+R2xdmxN23abvE8ZlpY8OWipW1T6+VI40fLo0RFY591XKvQ3qFDe6zMv0jv7/sazMv0jv7/s5z/kSpA+R1IiK3Em0Cokt97kbmvbt3e8q0fKitrNUXmqKNlbpWUznVV7vYjls5EZ5KKjV2pdewasdZrMy/SO/v+xrMy/SO/v8As4ej5T4g3C8Ora2Jivlw+oqnxxSJlfo0YqXuy6Kt13bE7ei3/wAlxXSrCmCQ6XVUrG/++8nR9KKuTY/ssqf+QnH378DrdZmX6Rf7/sazMv0i/wB/2cVV/wDqBQ070VqU6RthimlbNVtjltIiORI2Ki51RFRV2p2XU2uO4jiFFU4Syhip5I6qqSKRZZFatsrlslmr1Xv2W6borSXi/wCXQ6zMv0jv7/sazMv0rv7/ALOQn5ZLDSPemH5qiFlU+oh01tGkOzfl25lVttm51+gzquVjsLjnXFKKOne2Bk8SMqEc16OcjLK5WtyqjlS+9LLe4V1mszL9K7+/7GszL9K7+/7OfwDlDFjmtMatMstM5qPWlqUnjVHJdFR6InaipZLWN0BNrMy/Su/v+xrMy/Su/v8AshAE2szL9K7+/wCxrMy/Su/v+yEATazMv0rv7/sazMv0rv7/ALIQBNrMy/Su/v8AsazMv0rv7/shAE2szL9K7+/7GszL9K7+/wCyEATazMv0rv7/ALGszL9K7+/7IQBNrMy/Su/v+z1s0j5WI9yqma+38/EgM4vlmfaBu2+ah6eN81D0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABDUfJOJiGo+ScBpU81PsPS9FQMfCx+dyZmov52MubmdEju7+9gGvKuIYfBidG+lqEdkcqORzHWc1yLdHIvQqKiKbrm5nRI7u/vYObmdEju7+9gHJu5MU8zJtbrayqmlSNqzyuYjmtY9Ho1Ea1Gol027Lr1mdbyapayrlq9YqYah8sczZInNvG5jVaioitVNzl3op1PNzOiR3d/ewc3M6JHd397AOWouTdLQzwTNnqZJIZpZkdK9FzOkSzr7DVYlyflomRphUOIPkWOZjpaeoiYq53q/K9HpbLdy7W+Uh33NzOiR3d/ewc3M6JHd397BMWsTTjqLkxq9FRNbX1VLUxUkdNO+lc1ElRibL5mruVVsqWXbvNtVYfFVz0UsjpEdSS6WOy71yubtvvSzlN3zczokd3f3sHNzOiR3d/ewszc2zEVFOTl5L08tatRrtayJaptYtM1zNGsrVRb+bm22S6XsT0/J+kpo8PYySZUoHyPizOTylejkXNs/8AJd1jpebmdEju7+9g5uZ0SO7v72E1S9uQZySom0kdMtTVvjip5qaPM5l2xy2umxvRlSyr+dy9zLTaxp88ubVNTtdLZL3vu3/2x0PNzOiR3d/ewc3M6JHd397B9+/5kcpDyZgpVi1SurqZrYo4pGxPbaZGJZquu1VRbJa7cpexLDI8SbT5ppYX08yTRyRKl0ciKn/ZFRUVFVN3Sb3m5nRI7u/vYObmdEju7+9gvZT5/U8n6iph5UVrKJ0VViMCwQwukaqrZls10WyZlt09CXNkzktTSxSrW1VXUzSxMiSSV7UdCjVzNRmVqWs5EW63VbJdVOu5uZ0SO/v9Qc3M6JHd397AS0tDRvo43pJW1NW9y3V9Qrbp2IjWtRO4tGw5uZ0SO7v72Dm5nRI7u/vYBrwbDm5nRI7u/vYObmdEju7+9gGvBsObmdEju7+9g5uZ0SO7v72Aa8Gw5uZ0SO7v72Dm5nRI7u/vYBrwbDm5nRI7u/vYObmdEju7+9gGvBsObmdEju7+9g5uZ0SO7v72Aa8Gw5uZ0SO7v72Dm5nRI7u/vYBrzOL5Zn2l3m5nRI7u/vYYS0rad0b0cq3fbb9i/wD8A2LfNQ9PG+ah6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqPknExDUfJOAxp2rq0XluTyE6ur7CXI7iO93gY0/zWL7ifsSgYZHcR3u8BkdxHe7wMwBhkdxHe7wGR3Ed7vAzAGGR3Ed7vAZHcR3u8DMAYZHcR3u8BkdxHe7wMwBhkdxHe7wGR3Ed7vAzAGGR3Ed7vAZHcR3u8DMAYZHcR3u8BkdxHe7wMwBhkdxHe7wGR3Ed7vAzAGGR3Ed7vAZHcR3u8DMAYZHcR3u8BkdxHe7wMwBhkdxHe7wGR3Ed7vAzAGGR3Ed7vAZHcR3u8DMAYZHcR3u8BkdxHe7wMwBhkdxHe7wGR3Ed7vAzAGGR3Ed7vAZHcR3u8DMAYZHcR3u8CvVIqJFdyr/k6bdSlsrVfmxfifwoFhvmoenjfNQ9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQ1HyTiYhqPknAe0/zWL7ifsSkVP8ANYvuJ+xKB4c5y0rcSoeTj5MJnbDXPqIIonuYjku+RrbKipbbex0Zr8Uw2LFaZlPO6RjWTRTosdkXMx6PTei7LtS5PgcnjHK2rmhwBcKkSF1TNBLW3ajlZG6VsSxrdNiq5yp1+Qps05WozlLFhM1PTM00z4I8ta186K1quRz4kTyWqjVsuZV3XRLkqcj8MbJWSMWdrqqsirH2enkujej0a26bGq66qnW5209i5I0sGIQ1DK2uWOGqfVxUyvZo2SPzZl83MqLndvVbdFik9KmGcr6usShkqMISGGvgllp1jqkke5Y0urXIrWol03Lf7bEVPy8hdFX6Wnp3zUsMczWUVa2oRyvdkaxzkREa/NZFTam291NivJDDnYfQ0L31LoKOCWBiK9EVzZG5XZlRN9l2WsVpeR8LKKrcs1diM8lGlM1k8zI/JauZiNVrERqou5bfaN9CGr5aS4UtZFitBBSzU6U6MtWosT3SuciXe5rcqJkVVVU69i7L7Pk9ykhx6iq5mJC6SllWKRKSdKiNy5UciseiJmRUVOhNt0NNhfJmqrajEqnFX4hGs+rpTvqZoVqGOiVyo+8SZE2u2JtvZb7zqaSgdTUskM1bVVjnqqulnc1HrdLWTIjUb+SIPk25qn5dsdhVbiVXSQRQU0LZLRVrXvY5y5UjlaqNWN91TfdE27dhjFy+hloa2SOCjnmpZYmPWlrkmp0bJez3So3yUSy5vJ2dtzYN5HUb0m1ysrq10kCUzHzyNzRRo5HIjXNaiqqORFzOuuzeWuYZHUroZMaxSSbSNkZUrIxr2K3ciI1iMVNq3RWrfpuQauq5ZTQUNDOtFSNdVLJaWTEGpTeQqWyzI1UVXX8lFRt7Le1jOblRJTVtVpKaZzkp6NYaVZGfKzOe1G5kTZtRLrmVLJsTrsN5JRRU2ip8UxGB7nSummY+O8yyKiuzNVis6OhqW6LXUy/4fhrad0TFqGMWCngZlk2x6BVWNzVtfMire633biipPyrrKedtDLhMfOetRQLC2rvHaRj3Nej1YiqnkORUyouxd+y+EvLKWGgZJJQQQ1CVklJMs9Xkp4nMS91myLsXZa7Uuq9BsYeStKk8dTNV1dTVNqWVDqiVzMz3Ma5rWqjWo1Gojl2IibT1/JqJuldTYlXUs0lTJUrJC5m96Ijm5XNVqt2JvRVTrA2eH1UlZh8FTJCsTpWI5Y87X5b/APk1bKnahcKOF4bBhGGwUFMjtDC3K3Mt1XtUvCeUjgAAUAAAAAAAAAAAAAAAAK1X5sX4n8KWStV+bF+J/CgWG+ah6eN81D0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABDUfJOJiGo+ScB7T/NYvuJ+xKRU/zWL7ifsSgADFzkba/StgMgR6REcrduy3vMs7b2zJfquBkDHM3rTdf8grmtS6uRE7VAyBjmb1pvtvPNIzb5bdm1doGYI2ysciKi7FS97mWkZ6Te8DIGKuaioiuRFXclzxzsrmpbzlt7gMwYo5rlVEci232U8R7FvZzVt1KBmDFrkcl2qip1opkAAAAAAAAAAAAAAAAAAAArVfmxfifwpZK1X5sX4n8KBYb5qHp43zUPQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAENR8k4mIaj5JwHtP81i+4n7EpFT/ADWL7ifsSgDF7c7Fb1oZACDK5WKrk8tzkVU+xUPEjdn25lTMrui3iWABW0L7J9uXf/1JXoquj2bEdde5SQAQKx97ZdmfNe/QGMc1I9lrKtycAVsjsjUttRjm7+nYZ6Nc18qeZlJgBW0b9y5rKiJsVNhJIiq5luhVuvVsUlAFZY3K1Ey5LMVt7ntle9UyW8i1r9pYMWta3zWon2IBhEjkzZktddl7X/OxKAAAAAAAAAAAAAAAAAAAAArVfmxfifwpZK1X5sX4n8KBYb5qHp43zUPQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEU6XiUlPFS6AUI6+OKJkbo5LtaiLZE8TLnSLhy9yeJZWBir5p5q8fooBX50i4cvcniOdIuHL3J4ljV4/RQavH6KAV+dIuHL3J4jnSLhy9yeJY1eP0UGrx+igFfnSLhy9yeI50i4cvcniWNXj9FBq8fooBX50i4cvcniOdIuHL3J4ljV4/RQavH6KAV+dIuHL3J4jnSLhy9yeJY1eP0UGrx+igFfnSLhy9yeI50i4cvcniWNXj9FBq8fooBX50i4cvcniOdIuHL3J4ljV4/RQavH6KAV+dIuHL3J4jnSLhy9yeJY1eP0UGrx+igFfnSLhy9yeI50i4cvcniWNXj9FBq8fooBX50i4cvcniOdIuHL3J4ljV4/RQavH6KAV+dIuHL3J4jnSLhy9yeJY1eP0UGrx+igFfnSLhy9yeI50i4cvcniWNXj9FBq8fooBX50i4cvcniOdIuHL3J4ljV4/RQavH6KAV+dIuHL3J4jnSLhy9yeJY1eP0UGrx+igFfnSLhy9yeI50i4cvcniWNXj9FBq8fooBX50i4cvcniYuqm1SxtYx6WddVcnYpa1eP0UMmwsat0QDNu49AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/9k=)"
      ],
      "metadata": {
        "id": "fIfoBAPleP4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 3:** Agora voc√™ pode verificar se a sua instala√ß√£o do CUDA est√° funcionando corretamente executando o comando abaixo:"
      ],
      "metadata": {
        "id": "Rxqgbm_Hf5Zf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHrFpQGm931S",
        "outputId": "5c107fbf-49e5-45b8-cd65-831f897c4cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 4:** Execute o comando abaixo para instalar uma extens√£o para executar nvcc nas c√©lulas do Notebook."
      ],
      "metadata": {
        "id": "lBhCK8hzgaBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFBQZ1wW-XDO",
        "outputId": "ca7f33b2-477b-4faf-edb2-54ce4d872917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-n19ye5b2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-n19ye5b2\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=4dfc1db302622b9dbea419fca7265fd33794824fcb87713c7798b91cb1e2cc1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8s7f55_/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 5:** Carregue a extens√£o usando o c√≥digo fornecido abaixo:"
      ],
      "metadata": {
        "id": "tU3T5CPAgePq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXWXjfoo-fKV",
        "outputId": "4f48df46-6389-4c52-84bc-3fcc725efbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 6:** Execute o c√≥digo abaixo para verificar se o CUDA est√° funcionando corretamente ou n√£o.\n",
        "\n",
        " **Nota:** Para executar o c√≥digo em seu notebook, adicione a extens√£o `%%cu` no in√≠cio do seu c√≥digo.\n"
      ],
      "metadata": {
        "id": "htE4f37dgyPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "#include <iostream>\n",
        "\n",
        "__global__ void helloCUDA() {\n",
        "    printf(\"Hello from CUDA kernel!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    helloCUDA<<<1, 1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    std::cout << \"Hello from CPU!\" << std::endl;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFKBMavN-uyg",
        "outputId": "a38660b2-071d-448c-b931-fb616d6ef0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%cu` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 7:** Execute `nvidia-smi` para visualizar o gerenciamento do sistema NVIDIA, assim, exibir informa√ß√µes sobre a GPU NVIDIA, incluindo seu nome, uso de mem√≥ria e outros detalhes relevantes.\n"
      ],
      "metadata": {
        "id": "CROZihO2iY-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total --format=csv"
      ],
      "metadata": {
        "id": "PMTl33X7CHJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e288e869-9c85-45df-a111-d5417651d4a1",
        "id": "rlXVsDDfi6KK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 16 19:38:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üíªüéÆ Computa√ß√£o Heterog√™nea\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6D8EJuXAreCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminologia\n",
        "- <font color=\"orange\">**Host:**</font> A CPU e sua mem√≥ria (mem√≥ria do host)\n",
        "- <font color=\"orange\">**Device:**</font> A GPU e sua mem√≥ria (mem√≥ria do dispositivo)\n",
        "\n",
        "\n",
        "<img src=\"https://imgur.com/Bp1by83.png\" alt=\"Computa√ßƒÅo Heterog√™nea\" width=\"800\" height=\"600\" style=\"background-color:white;\">\n"
      ],
      "metadata": {
        "id": "lFMjkFdS1r68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hello World\n",
        "\n",
        "Vamos rever o c√≥digo em partes:\n",
        "\n",
        "<font color=\"orange\">**Colab `nvcc_plugin`**</font>\n",
        "```cpp\n",
        "%%cu\n",
        "```\n",
        "`%%cu` ‚Üí Essa linha indica ao Google Colab que o c√≥digo a seuir √© um arquivo CUDA. No ambiente de desenvolvimento normal, voc√™ teria que compilar o c√≥digo usando `nvcc hello.cu -o hello`.\n",
        "\n",
        "<font color=\"orange\">**Fun√ß√£o do kernel CUDA:**</font>\n",
        "\n",
        "---\n",
        "```cpp\n",
        "__global__ void helloCUDA() {\n",
        "    printf(\"Hello from CUDA kernel!\\n\");\n",
        "}\n",
        "```\n",
        "\n",
        "Esta fun√ß√£o √© um kernel CUDA. A palavra-chave `__global__` indica que a fun√ß√£o ser√° executada na GPU (dispositivo). O kernel imprime \"Hello from CUDA kernel!\" no console.\n",
        "\n",
        "\n",
        "<font color=\"orange\">**Fun√ß√£o principal:**</font>\n",
        "\n",
        "---\n",
        "```cpp\n",
        "int main() {\n",
        "    helloCUDA<<<1, 1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    std::cout << \"Hello from CPU!\" << std::endl;\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "A fun√ß√£o `main` √© o ponto de entrada do programa. Ela faz o seguinte:\n",
        "\n",
        "1. `helloCUDA<<<1, 1>>>();` ‚Üí Lan√ßa o kernel `helloCUDA` na GPU. A explica√ßƒÅo dos par√¢metros ficar√° para logo mais.\n",
        "2. `cudaDeviceSynchronize();` ‚Üí Sincroniza a execu√ß√£o da CPU e GPU, garantindo que a GPU termine a execu√ß√£o do kernel antes de continuar.\n",
        "3. `std::cout << \"Hello from CPU!\" << std::endl;` ‚Üí Imprime \"Hello from CPU!\" no console.\n",
        "\n",
        "O programa imprime \"Hello from CUDA kernel!\" a partir da execu√ß√£o do kernel na GPU e, em seguida, \"Hello from CPU!\" a partir da execu√ß√£o na CPU."
      ],
      "metadata": {
        "id": "9lzkDrQB04hP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üíª Fluxo da Programa√ßƒÅo com CUDA C/C++\n",
        "---\n"
      ],
      "metadata": {
        "id": "eEbzFvwAuD91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- üí° Vamos para um exemplo mais interessante.\n",
        "- ‚û°Ô∏è Come√ßaremos adicionando dois n√∫meros inteiros e aumentando para a adi√ß√£o de vetores.\n",
        "\n",
        "<font color=\"orange\">**Um kernel simples para adicionar dois inteiros**</font>\n",
        "\n",
        "---\n",
        "```cpp\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    *c = *a + *b;\n",
        "}\n",
        "```\n",
        "\n",
        "üìù Como antes, `__global__` √© uma palavra-chave CUDA C/C++ que significa:\n",
        "- `add()` ser√° executado no `device`.\n",
        "- `add()` ser√° chamado a partir do `host`.\n",
        "\n",
        "<font color=\"orange\">**Adi√ß√£o no Device**</font>\n",
        "\n",
        "---\n",
        "- Observe que usamos ponteiros para as vari√°veis:\n",
        "\n",
        "```cpp\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    *c = *a + *b;\n",
        "}\n",
        "```\n",
        "\n",
        "- `add()` √© executado no **device**, ent√£o `a`, `b` e `c` devem apontar para a mem√≥ria do **device**.\n",
        "\n",
        "- **Precisamos alocar mem√≥ria na GPU. üíæ**"
      ],
      "metadata": {
        "id": "LVfvZLC1aIvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"orange\">**Fluxo de processamento**</font>\n",
        "\n",
        "---\n",
        "A mem√≥ria do host e do device s√£o entidades separadas:\n",
        "- üñ•Ô∏è Os ponteiros do **device** apontam para a mem√≥ria da GPU.\n",
        "  - üîÑ Podem ser passados para/de c√≥digo do host.\n",
        "  - üö´ N√£o podem ser desreferenciados no c√≥digo do host.\n",
        "- üíª Os ponteiros do **host** apontam para a mem√≥ria da CPU.\n",
        "  - üîÑ Podem ser passados para/de c√≥digo do device.\n",
        "  - üö´ N√£o podem ser desreferenciados no c√≥digo do device.\n",
        "\n",
        "API simples do CUDA para lidar com a mem√≥ria do device:\n",
        "- `cudaMalloc()`, `cudaFree()`, `cudaMemcpy()`\n",
        "- üß© Semelhantes aos equivalentes em C: `malloc()`, `free()`, `memcpy()`\n",
        "\n",
        "<font color=\"orange\">**Fluxo Simples de Processamento**</font>\n",
        "\n",
        "---\n",
        "<img src=\"https://imgur.com/XTP3RWY.png\" alt=\"Computa√ßƒÅo Heterog√™nea\" width=\"800\" height=\"600\" style=\"background-color:white;\">\n",
        "<img src=\"https://imgur.com/PJtY1HC.png\" alt=\"Computa√ßƒÅo Heterog√™nea\" width=\"800\" height=\"600\" style=\"background-color:white;\">\n",
        "<img src=\"https://imgur.com/tsgXmtC.png\" alt=\"Computa√ßƒÅo Heterog√™nea\" width=\"800\" height=\"600\" style=\"background-color:white;\">\n"
      ],
      "metadata": {
        "id": "B0Bl46PWnxdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Segue o c√≥digo completo:**"
      ],
      "metadata": {
        "id": "9pAZeBqv0jkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    int a, b, c;\n",
        "\n",
        "    // c√≥pias do host de a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    // c√≥pias do device de a, b, c\n",
        "    int size = sizeof(int);\n",
        "\n",
        "    // Inicializar seed para gerar n√∫meros aleat√≥rios\n",
        "    srand(time(NULL));\n",
        " \n",
        "    // Alocar espa√ßo para c√≥pias do device de a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Configurar entrada\n",
        "    a = 2;\n",
        "    b = 7;\n",
        "\n",
        "    // Copiar entradas para o device\n",
        "    cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßar kernel add() na GPU\n",
        "    add<<<1, 1>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copiar resultado de volta para o host\n",
        "    cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Valor final: \" << c << std::endl;\n",
        "\n",
        "    // Limpar\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3iZioYFrbSE",
        "outputId": "1b20dd5f-e6dd-4b43-baa1-ec308502f93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor final: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#‚¨õ Blocos\n",
        "---\n",
        "- ‚úÖ A computa√ß√£o GPU √© sobre paralelismo massivo!\n",
        "- ‚ûï Vamos ver um exemplo de adi√ßƒÅo de vetores."
      ],
      "metadata": {
        "id": "UgpPedbH1Ei9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "\n",
        "#define N 512\n",
        "\n",
        "void random_ints(int *arr, int num) {\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_array(const char *name, int *arr, int num) {\n",
        "    std::cout << name << \": \";\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        std::cout << arr[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int *a, *b, *c;        // c√≥pias do host de a, b, c\n",
        "    int *d_a, *d_b, *d_c;  // c√≥pias do device de a, b, c\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Alocar espa√ßo para c√≥pias do device de a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Alocar espa√ßo e configurar valores de entrada para c√≥pias do host de a, b, c\n",
        "    a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    c = (int *)malloc(size);\n",
        "\n",
        "    // Copiar entradas para o device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßar kernel add() na GPU com N blocos\n",
        "    add<<<N, 1>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copiar resultado de volta para o host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Exibir os vetores a, b e c no terminal\n",
        "    print_array(\"Vetor a\", a, N);\n",
        "    print_array(\"Vetor b\", b, N);\n",
        "    print_array(\"Vetor c (resultado)\", c, N);\n",
        "\n",
        "    // Limpar\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsDYIC5owmyF",
        "outputId": "95ca8509-3cce-4e58-c412-2e136ee00070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor a: 83 86 77 15 93 35 86 92 49 21 62 27 90 59 63 26 40 26 72 36 11 68 67 29 82 30 62 23 67 35 29 2 22 58 69 67 93 56 11 42 29 73 21 19 84 37 98 24 15 70 13 26 91 80 56 73 62 70 96 81 5 25 84 27 36 5 46 29 13 57 24 95 82 45 14 67 34 64 43 50 87 8 76 78 88 84 3 51 54 99 32 60 76 68 39 12 26 86 94 39 95 70 34 78 67 1 97 2 17 92 52 56 1 80 86 41 65 89 44 19 40 29 31 17 97 71 81 75 9 27 67 56 97 53 86 65 6 83 19 24 28 71 32 29 3 19 70 68 8 15 40 49 96 23 18 45 46 51 21 55 79 88 64 28 41 50 93 0 34 64 24 14 87 56 43 91 27 65 59 36 32 51 37 28 75 7 74 21 58 95 29 37 35 93 18 28 43 11 28 29 76 4 43 63 13 38 6 40 4 18 28 88 69 17 17 96 24 43 70 83 90 99 72 25 44 90 5 39 54 86 69 82 42 64 97 7 55 4 48 11 22 28 99 43 46 68 40 22 11 10 5 1 61 30 78 5 20 36 44 26 22 65 8 16 82 58 24 37 62 24 0 36 52 99 79 50 68 71 73 31 81 30 33 94 60 63 99 81 99 96 59 73 13 68 90 95 26 66 84 40 90 84 76 42 36 7 45 56 79 18 87 12 48 72 59 9 36 10 42 87 6 1 13 72 21 55 19 99 21 4 39 11 40 67 5 28 27 50 84 58 20 24 22 69 96 81 30 84 92 72 72 50 25 85 22 99 40 42 98 13 98 90 24 90 9 81 19 36 32 55 94 4 79 69 73 76 50 55 60 42 79 84 93 5 21 67 4 13 61 54 26 59 44 2 2 6 84 21 42 68 28 89 72 8 58 98 36 8 53 48 3 33 33 48 90 54 67 46 68 29 0 46 88 97 49 90 3 33 63 97 53 92 86 25 52 96 75 88 57 29 36 60 14 21 60 4 28 27 50 48 56 2 94 97 99 43 39 2 28 3 0 81 47 38 59 51 35 34 39 92 15 27 4 29 49 64 85 29 43 35 77 0 38 71 49 89 67 88 92 95 43 44 29 90 82 40 41 69 26 32 61 42 60 17 23 61 81 9 90 25 96 67 \n",
            "Vetor b: 77 34 90 26 24 57 14 68 5 58 12 86 0 46 26 94 16 52 78 29 46 90 47 70 51 80 31 93 57 27 12 86 14 55 12 90 12 79 10 69 89 74 55 41 20 33 87 88 38 66 70 84 56 17 6 60 49 37 5 59 17 18 45 83 73 58 73 37 89 83 7 78 57 14 71 29 0 59 18 38 25 88 74 33 57 81 93 58 70 99 17 39 69 63 22 94 73 47 31 62 82 90 92 91 57 15 21 57 74 91 47 51 31 21 37 40 54 30 98 25 81 16 16 2 31 39 96 4 38 80 18 21 70 62 12 79 77 85 36 4 76 83 7 59 57 44 99 11 27 50 36 60 18 5 63 49 44 11 5 34 91 75 55 14 89 68 93 18 5 82 22 82 17 30 93 74 26 93 86 53 43 74 14 13 79 77 62 75 88 19 10 32 94 17 46 35 37 91 53 43 73 28 25 91 10 18 17 36 63 55 90 58 30 4 71 61 33 85 89 73 4 51 5 50 68 3 85 6 95 39 49 20 67 26 63 77 96 81 65 60 36 55 70 18 11 42 32 96 79 21 70 84 72 27 34 40 83 72 98 30 63 47 50 30 73 14 59 22 47 24 82 35 32 4 54 43 98 86 40 78 59 62 62 83 41 48 23 24 72 22 54 35 21 57 65 47 71 76 69 18 1 3 53 33 7 59 28 6 97 20 84 8 34 98 91 76 98 15 52 71 89 59 6 10 16 24 9 39 0 78 9 53 81 14 38 89 26 67 47 23 87 31 32 22 81 75 50 79 90 54 50 31 13 57 94 81 81 3 20 33 82 81 87 15 96 25 4 22 92 51 97 32 34 81 6 15 57 8 95 99 62 97 83 76 54 77 9 87 32 82 21 66 63 60 82 11 85 86 85 30 90 83 14 76 16 20 92 25 28 39 25 90 36 60 18 43 37 28 82 21 10 55 88 25 15 70 37 53 8 22 83 50 57 97 27 26 69 71 51 49 10 28 39 98 88 10 93 77 90 76 99 52 31 87 77 99 57 66 52 17 41 35 68 98 84 95 76 5 66 28 54 28 8 93 78 97 55 72 74 45 0 25 97 83 12 27 82 21 93 34 39 34 21 59 85 57 54 61 62 72 41 16 52 50 62 82 99 17 54 73 15 6 \n",
            "Vetor c (resultado): 160 120 167 41 117 92 100 160 54 79 74 113 90 105 89 120 56 78 150 65 57 158 114 99 133 110 93 116 124 62 41 88 36 113 81 157 105 135 21 111 118 147 76 60 104 70 185 112 53 136 83 110 147 97 62 133 111 107 101 140 22 43 129 110 109 63 119 66 102 140 31 173 139 59 85 96 34 123 61 88 112 96 150 111 145 165 96 109 124 198 49 99 145 131 61 106 99 133 125 101 177 160 126 169 124 16 118 59 91 183 99 107 32 101 123 81 119 119 142 44 121 45 47 19 128 110 177 79 47 107 85 77 167 115 98 144 83 168 55 28 104 154 39 88 60 63 169 79 35 65 76 109 114 28 81 94 90 62 26 89 170 163 119 42 130 118 186 18 39 146 46 96 104 86 136 165 53 158 145 89 75 125 51 41 154 84 136 96 146 114 39 69 129 110 64 63 80 102 81 72 149 32 68 154 23 56 23 76 67 73 118 146 99 21 88 157 57 128 159 156 94 150 77 75 112 93 90 45 149 125 118 102 109 90 160 84 151 85 113 71 58 83 169 61 57 110 72 118 90 31 75 85 133 57 112 45 103 108 142 56 85 112 58 46 155 72 83 59 109 48 82 71 84 103 133 93 166 157 113 109 140 92 95 177 101 111 122 105 171 118 113 108 34 125 155 142 97 142 153 58 91 87 129 75 43 66 73 62 176 38 171 20 82 170 150 85 134 25 94 158 95 60 19 82 37 79 28 138 21 82 48 64 121 81 43 117 53 117 131 81 107 55 54 91 177 156 80 163 182 126 122 81 38 142 116 180 121 45 118 46 180 171 111 105 105 106 23 58 124 106 191 36 113 150 79 91 107 63 155 141 141 181 176 81 75 144 13 100 93 136 47 125 107 62 84 17 169 107 127 98 118 172 86 84 74 118 128 33 81 87 28 123 69 108 108 97 104 74 150 50 10 101 176 122 64 160 40 86 71 119 136 142 143 122 79 122 144 159 108 78 46 88 53 119 148 14 121 104 140 124 155 54 125 184 176 142 96 68 80 20 41 116 115 136 143 146 111 39 105 120 69 55 12 122 127 161 140 101 117 80 77 25 135 154 61 116 149 109 185 129 82 78 50 149 167 97 95 130 88 104 102 58 112 67 85 143 180 26 144 98 111 73 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"orange\">**Vamos quebrar o c√≥digo**</font>\n",
        "\n",
        "---\n",
        "**üìñ Terminologia**\n",
        "\n",
        "\n",
        "Ao trabalhar com CUDA, √© importante entender a terminologia usada:\n",
        "\n",
        "- Cada invoca√ß√£o paralela da fun√ß√£o `add()` √© chamada de **bloco**.\n",
        "- O conjunto de blocos √© chamado de **grid**.\n",
        "- Cada invoca√ß√£o pode se referir ao seu √≠ndice de bloco usando `blockIdx.x`.\n",
        "\n",
        "**üîÄ Usando `blockIdx.x`**\n",
        "\n",
        "- No kernel `add`, a vari√°vel `blockIdx.x` √© usada para indexar os vetores:\n",
        "\n",
        "```cpp\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "```\n",
        "\n",
        "- Ao usar `blockIdx.x` para indexar os vetores, cada bloco lida com um √≠ndice diferente. No device, cada bloco pode ser executado em paralelo, permitindo que a adi√ß√£o dos elementos dos vetores `a` e `b` seja feita de forma eficiente e r√°pida.\n",
        "\n",
        "**üöÄ Lan√ßando o kernel**\n",
        "\n",
        "- O kernel `add` √© lan√ßado na GPU com a seguinte linha de c√≥digo:\n",
        "\n",
        "```cpp\n",
        "add<<<N, 1>>>(d_a, d_b, d_c);\n",
        "```\n",
        "\n",
        "- Aqui, `N` representa o n√∫mero de blocos e `1` representa o n√∫mero de threads por bloco. No nosso caso, cada bloco possui apenas uma thread. O kernel ser√° lan√ßado com `N` blocos, ou seja, `N` threads no total.\n",
        "\n",
        "**üì¶ Gerenciamento de Mem√≥ria**\n",
        "\n",
        "Existem duas etapas principais no gerenciamento de mem√≥ria neste c√≥digo:\n",
        "\n",
        "1. **Alocar espa√ßo na mem√≥ria do host e do device**: O espa√ßo na mem√≥ria do host √© alocado usando a fun√ß√£o `malloc`, enquanto o espa√ßo na mem√≥ria do device √© alocado usando a fun√ß√£o `cudaMalloc`.\n",
        "\n",
        "```cpp\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "```\n",
        "\n",
        "2. **Copiar dados entre a mem√≥ria do host e do device**: Os dados s√£o copiados entre a mem√≥ria do host e do device usando a fun√ß√£o `cudaMemcpy`. A dire√ß√£o da c√≥pia √© determinada pelo √∫ltimo par√¢metro, que pode ser `cudaMemcpyHostToDevice` ou `cudaMemcpyDeviceToHost`.\n",
        "\n",
        "```cpp\n",
        "cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "```\n",
        "\n",
        "Inicialmente, os dados dos vetores `a` e `b` s√£o copiados do host para o device. Depois que o kernel `add` √© executado, os resultados no vetor `c` s√£o copiados do device para o host."
      ],
      "metadata": {
        "id": "kX32u3LMziDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üßµ CUDA Threads\n",
        "---\n",
        "- üìñ Terminologia: um bloco pode ser dividido em threads paralelas\n",
        "- ‚ÜîÔ∏è N√≥s usamos `threadIdx.x` ao inv√©s de `blockIdx.x`\n",
        "- üöÄ Lan√ßar kernel `add()` na GPU com N threads\n",
        "```\n",
        "add<<<1, N>>>(d_a, d_b, d_c);\n",
        "```\n",
        "- üñ•Ô∏è Segue o c√≥digo completo"
      ],
      "metadata": {
        "id": "-tjNFMxE4gaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) \n",
        "{ \n",
        "    c[threadIdx.x] = a[threadIdx.x] + b[threadIdx.x]; \n",
        "}\n",
        "\n",
        "#define N 500\n",
        "\n",
        "void random_ints(int *arr, int num) {\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_array(const char *name, int *arr, int num) {\n",
        "    std::cout << name << \": \";\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        std::cout << arr[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int *a, *b, *c;        // c√≥pias do host de a, b, c\n",
        "    int *d_a, *d_b, *d_c;  // c√≥pias do device de a, b, c\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Alocar espa√ßo para c√≥pias do device de a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Alocar espa√ßo e configurar valores de entrada para c√≥pias do host de a, b, c\n",
        "    a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    c = (int *)malloc(size);\n",
        "\n",
        "    // Copiar entradas para o device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßar kernel add() na GPU com N Threads\n",
        "    add<<<1, N>>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copiar resultado de volta para o host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Exibir os vetores a, b e c no terminal\n",
        "    print_array(\"Vetor a\", a, N);\n",
        "    print_array(\"Vetor b\", b, N);\n",
        "    print_array(\"Vetor c (resultado)\", c, N);\n",
        "\n",
        "    // Limpar\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "Sm2jOivo49n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67c8b36-4db2-43f4-9e91-de8b4d3fd804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor a: 83 86 77 15 93 35 86 92 49 21 62 27 90 59 63 26 40 26 72 36 11 68 67 29 82 30 62 23 67 35 29 2 22 58 69 67 93 56 11 42 29 73 21 19 84 37 98 24 15 70 13 26 91 80 56 73 62 70 96 81 5 25 84 27 36 5 46 29 13 57 24 95 82 45 14 67 34 64 43 50 87 8 76 78 88 84 3 51 54 99 32 60 76 68 39 12 26 86 94 39 95 70 34 78 67 1 97 2 17 92 52 56 1 80 86 41 65 89 44 19 40 29 31 17 97 71 81 75 9 27 67 56 97 53 86 65 6 83 19 24 28 71 32 29 3 19 70 68 8 15 40 49 96 23 18 45 46 51 21 55 79 88 64 28 41 50 93 0 34 64 24 14 87 56 43 91 27 65 59 36 32 51 37 28 75 7 74 21 58 95 29 37 35 93 18 28 43 11 28 29 76 4 43 63 13 38 6 40 4 18 28 88 69 17 17 96 24 43 70 83 90 99 72 25 44 90 5 39 54 86 69 82 42 64 97 7 55 4 48 11 22 28 99 43 46 68 40 22 11 10 5 1 61 30 78 5 20 36 44 26 22 65 8 16 82 58 24 37 62 24 0 36 52 99 79 50 68 71 73 31 81 30 33 94 60 63 99 81 99 96 59 73 13 68 90 95 26 66 84 40 90 84 76 42 36 7 45 56 79 18 87 12 48 72 59 9 36 10 42 87 6 1 13 72 21 55 19 99 21 4 39 11 40 67 5 28 27 50 84 58 20 24 22 69 96 81 30 84 92 72 72 50 25 85 22 99 40 42 98 13 98 90 24 90 9 81 19 36 32 55 94 4 79 69 73 76 50 55 60 42 79 84 93 5 21 67 4 13 61 54 26 59 44 2 2 6 84 21 42 68 28 89 72 8 58 98 36 8 53 48 3 33 33 48 90 54 67 46 68 29 0 46 88 97 49 90 3 33 63 97 53 92 86 25 52 96 75 88 57 29 36 60 14 21 60 4 28 27 50 48 56 2 94 97 99 43 39 2 28 3 0 81 47 38 59 51 35 34 39 92 15 27 4 29 49 64 85 29 43 35 77 0 38 71 49 89 67 88 92 95 43 44 29 90 82 40 41 69 26 32 \n",
            "Vetor b: 61 42 60 17 23 61 81 9 90 25 96 67 77 34 90 26 24 57 14 68 5 58 12 86 0 46 26 94 16 52 78 29 46 90 47 70 51 80 31 93 57 27 12 86 14 55 12 90 12 79 10 69 89 74 55 41 20 33 87 88 38 66 70 84 56 17 6 60 49 37 5 59 17 18 45 83 73 58 73 37 89 83 7 78 57 14 71 29 0 59 18 38 25 88 74 33 57 81 93 58 70 99 17 39 69 63 22 94 73 47 31 62 82 90 92 91 57 15 21 57 74 91 47 51 31 21 37 40 54 30 98 25 81 16 16 2 31 39 96 4 38 80 18 21 70 62 12 79 77 85 36 4 76 83 7 59 57 44 99 11 27 50 36 60 18 5 63 49 44 11 5 34 91 75 55 14 89 68 93 18 5 82 22 82 17 30 93 74 26 93 86 53 43 74 14 13 79 77 62 75 88 19 10 32 94 17 46 35 37 91 53 43 73 28 25 91 10 18 17 36 63 55 90 58 30 4 71 61 33 85 89 73 4 51 5 50 68 3 85 6 95 39 49 20 67 26 63 77 96 81 65 60 36 55 70 18 11 42 32 96 79 21 70 84 72 27 34 40 83 72 98 30 63 47 50 30 73 14 59 22 47 24 82 35 32 4 54 43 98 86 40 78 59 62 62 83 41 48 23 24 72 22 54 35 21 57 65 47 71 76 69 18 1 3 53 33 7 59 28 6 97 20 84 8 34 98 91 76 98 15 52 71 89 59 6 10 16 24 9 39 0 78 9 53 81 14 38 89 26 67 47 23 87 31 32 22 81 75 50 79 90 54 50 31 13 57 94 81 81 3 20 33 82 81 87 15 96 25 4 22 92 51 97 32 34 81 6 15 57 8 95 99 62 97 83 76 54 77 9 87 32 82 21 66 63 60 82 11 85 86 85 30 90 83 14 76 16 20 92 25 28 39 25 90 36 60 18 43 37 28 82 21 10 55 88 25 15 70 37 53 8 22 83 50 57 97 27 26 69 71 51 49 10 28 39 98 88 10 93 77 90 76 99 52 31 87 77 99 57 66 52 17 41 35 68 98 84 95 76 5 66 28 54 28 8 93 78 97 55 72 74 45 0 25 97 83 12 27 82 21 \n",
            "Vetor c (resultado): 144 128 137 32 116 96 167 101 139 46 158 94 167 93 153 52 64 83 86 104 16 126 79 115 82 76 88 117 83 87 107 31 68 148 116 137 144 136 42 135 86 100 33 105 98 92 110 114 27 149 23 95 180 154 111 114 82 103 183 169 43 91 154 111 92 22 52 89 62 94 29 154 99 63 59 150 107 122 116 87 176 91 83 156 145 98 74 80 54 158 50 98 101 156 113 45 83 167 187 97 165 169 51 117 136 64 119 96 90 139 83 118 83 170 178 132 122 104 65 76 114 120 78 68 128 92 118 115 63 57 165 81 178 69 102 67 37 122 115 28 66 151 50 50 73 81 82 147 85 100 76 53 172 106 25 104 103 95 120 66 106 138 100 88 59 55 156 49 78 75 29 48 178 131 98 105 116 133 152 54 37 133 59 110 92 37 167 95 84 188 115 90 78 167 32 41 122 88 90 104 164 23 53 95 107 55 52 75 41 109 81 131 142 45 42 187 34 61 87 119 153 154 162 83 74 94 76 100 87 171 158 155 46 115 102 57 123 7 133 17 117 67 148 63 113 94 103 99 107 91 70 61 97 85 148 23 31 78 76 122 101 86 78 100 154 85 58 77 145 96 98 66 115 146 129 80 141 85 132 53 128 54 115 129 92 67 153 124 197 182 99 151 72 130 152 178 67 114 107 64 162 106 130 77 57 64 110 103 150 94 156 30 49 75 112 42 43 69 70 93 103 21 97 80 55 153 110 175 119 19 91 82 129 126 11 38 43 74 93 97 20 102 31 122 177 95 68 173 118 139 119 73 112 116 54 121 121 117 148 92 188 144 74 121 22 138 113 117 113 58 114 37 161 150 160 91 146 80 64 64 171 135 190 37 55 148 10 28 118 62 121 158 106 99 85 82 138 98 51 155 60 171 93 74 121 158 118 19 138 134 88 63 123 131 104 130 83 66 160 54 28 85 113 187 85 150 21 76 100 125 135 113 96 80 140 121 90 158 94 82 44 82 97 71 117 101 55 53 119 119 107 51 104 125 138 141 127 12 121 80 90 157 146 90 90 138 112 133 96 158 67 44 45 64 117 162 169 124 119 40 143 28 92 99 57 182 145 185 147 167 117 89 29 115 179 123 53 96 108 53 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üß© Combinando Threads e Blocos\n",
        "---"
      ],
      "metadata": {
        "id": "s7JJyfW18Aja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- üõ†Ô∏è Vamos adaptar a adi√ß√£o de vetores para usar blocos e threads. \n",
        "- üóÇÔ∏è Primeiro, vamos discutir a indexa√ß√£o de dados...\n",
        "\n",
        "<font color=\"orange\">**üìä Indexando Arrays com Blocos e Threads**</font>\n",
        "\n",
        "- ü§î N√£o √© mais t√£o simples quanto usar blockIdx.x e threadIdx.x.\n",
        "- üéõÔ∏è Considere indexar um array com um elemento por thread (8 threads/bloco).\n",
        "\n",
        "<img src=\"https://imgur.com/6LoIWyQ.png\" alt=\"array\">    \n",
        "\n",
        "- üí° Com M threads/bloco, um √≠ndice √∫nico para cada thread √© dado por:\n",
        "\t- `int index = threadIdx.x + blockIdx.x * M;` \n",
        "\n",
        "- üö© Qual thread operar√° no elemento vermelho?\n",
        "\n",
        "<img src=\"https://imgur.com/WosLd0A.png\" alt=\"array\">    \n",
        "\n",
        "```cpp\n",
        "int index = threadIdx.x + blockIdx.x * M;\n",
        "          =      5      +     2      * 8;\n",
        "          = 21;\n",
        "```\n",
        "\n",
        "- üìù O que vai mudar no c√≥digo?\n",
        "    - Use a vari√°vel interna `blockDim.x` para threads por bloco:\n",
        "    ```cpp\n",
        "        __global__ void add(int *a, int *b, int *c, int n) \n",
        "        { \n",
        "            int index = threadIdx.x + blockIdx.x * blockDim.x; \n",
        "            if (index < n) \n",
        "                c[index] = a[index] + b[index]; \n",
        "        }\n",
        "    ```\n",
        "    - Lance o kernel `add`, sendo `N` n√∫mero de elementos do vetor, e `M` quantidade de threads :\n",
        "    ```cpp\n",
        "        add<<<(N + M-1)/M , M>>>(d_a, d_b, d_c, N);\n",
        "    ```\n",
        "- üëÄ Vamos olhar o c√≥digo completo:"
      ],
      "metadata": {
        "id": "jDWFHVcLRRdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c, int n) { \n",
        "    int index = threadIdx.x + blockIdx.x * blockDim.x; \n",
        "    if (index < n){\n",
        "        printf(\"thread %d do bloco %d , executou index %d que soma %d + %d\\n\",threadIdx.x,blockIdx.x,index,a[index],b[index]);\n",
        "        c[index] = a[index] + b[index]; \n",
        "    }\n",
        "}\n",
        "\n",
        "#define N 50\n",
        "#define THREADS_PER_BLOCK 5\n",
        "\n",
        "void random_ints(int *arr, int num) {\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_array(const char *name, int *arr, int num) {\n",
        "    std::cout << name << \": \";\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        std::cout << arr[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int *a, *b, *c;        // c√≥pias do host de a, b, c\n",
        "    int *d_a, *d_b, *d_c;  // c√≥pias do device de a, b, c\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Alocar espa√ßo para c√≥pias do device de a, b, c\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Alocar espa√ßo e configurar valores de entrada para c√≥pias do host de a, b, c\n",
        "    a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    c = (int *)malloc(size);\n",
        "\n",
        "    // Copiar entradas para o device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßar kernel add() na GPU com N Threads\n",
        "    add<<<(N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Copiar resultado de volta para o host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Exibir os vetores a, b e c no terminal\n",
        "    print_array(\"Vetor a\", a, N);\n",
        "    print_array(\"Vetor b\", b, N);\n",
        "    print_array(\"Vetor c (resultado)\", c, N);\n",
        "\n",
        "    // Limpar\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zdUAsQ6TBra",
        "outputId": "9bc586a4-82b7-4876-cc74-a6a0f8c357d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thread 0 do bloco 2 , executou index 4 que soma 93 + 63\n",
            "thread 1 do bloco 2 , executou index 5 que soma 35 + 26\n",
            "thread 0 do bloco 4 , executou index 8 que soma 49 + 72\n",
            "thread 1 do bloco 4 , executou index 9 que soma 21 + 36\n",
            "thread 0 do bloco 0 , executou index 0 que soma 83 + 62\n",
            "thread 1 do bloco 0 , executou index 1 que soma 86 + 27\n",
            "thread 0 do bloco 3 , executou index 6 que soma 86 + 40\n",
            "thread 1 do bloco 3 , executou index 7 que soma 92 + 26\n",
            "thread 0 do bloco 1 , executou index 2 que soma 77 + 90\n",
            "thread 1 do bloco 1 , executou index 3 que soma 15 + 59\n",
            "Vetor a: 83 86 77 15 93 35 86 92 49 21 \n",
            "Vetor b: 62 27 90 59 63 26 40 26 72 36 \n",
            "Vetor c (resultado): 145 113 167 74 156 61 126 118 121 57 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ü§ù THREADS COOPERATIVAS\n",
        "---\n",
        "\n",
        ">ü§î Por que se preocupar com Threads? \n",
        "\n",
        "As Threads parecem desnecess√°rias:\n",
        "- Elas adicionam um n√≠vel de complexidade\n",
        "- O que ganhamos com isso?\n",
        "\n",
        "Ao contr√°rio dos blocos paralelos, as threads t√™m mecanismos para:\n",
        "- üì® Comunicar-se \n",
        "- ‚è±Ô∏è Sincronizar-se \n",
        "\n",
        "Para analisar mais de perto, precisamos de um novo exemplo‚Ä¶ üßê"
      ],
      "metadata": {
        "id": "LAE_PekEHJTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìèüñäÔ∏è Stencil 1D \n",
        "\n",
        "- Stencil √© um algoritmo de processamento de sinal ou imagem, que realiza uma opera√ß√£o de convolu√ß√£o em uma dimens√£o, aplicando um filtro (ou m√°scara) sobre os elementos de um vetor ou uma matriz.\n",
        "\n",
        "- O uso de stencil em CUDA pode ser extremamente ben√©fico, especialmente em aplica√ß√µes que requerem alto grau de paralelismo e acesso eficiente √† mem√≥ria.\n",
        "\n",
        "<font color=\"orange\">**Funcionamento**</font>\n",
        "\n",
        "- Nosso caso vamos usar stencil de 1 dimensƒÅo.\n",
        "- Cada elemento de sa√≠da √© a soma dos elementos de entrada dentro de um raio.\n",
        "- Se o raio √© 3, ent√£o cada elemento de sa√≠da √© a soma de 7 elementos de entrada:\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://imgur.com/ubDnvyb.png\" alt=\"1dstencil\" width=800 heigh=100>\n",
        "</center>\n",
        "<!-- https://imgur.com/cBWLQzV.png  -->\n",
        "\n",
        "<font color=\"orange\">**Implementa√ß√£o dentro de um bloco**</font>\n",
        "\n",
        "‚úÖ Cada _thread_ processa um elemento de sa√≠da\n",
        "\n",
        "üîÑ Elementos de entrada s√£o lidos v√°rias vezes\n",
        "- Com raio 3, cada elemento de entrada √© lido 7 vezes \n",
        "<center>\n",
        "  <img src=\"https://imgur.com/uJhcxI6.gif\" alt=\"1dstencil\" width=700 heigh=100>\n",
        "</center>\n",
        "\n",
        "<font color=\"orange\">**Compartilhando Dados Entre Threads**</font>\n",
        "\n",
        "- üìö Dentro de um bloco, as __threads__ compartilham dados atrav√©s da ***mem√≥ria compartilhada*** (__shared memory__)\n",
        "    - üöÄ Mem√≥ria extremamente r√°pida no chip, gerenciada pelo usu√°rio.\n",
        "- üîñ Declare usando `__shared__`, alocado por bloco.\n",
        "- ‚ùå Dados n√£o s√£o vis√≠veis para threads em outros blocos.\n",
        "\n",
        "<font color=\"orange\">**Implementa√ß√£o com Mem√≥ria Compartilhada**</font>\n",
        "\n",
        "- üì¶ Cache de dados na mem√≥ria compartilhada\n",
        "    - üìñ Leia (`blockDim.x + 2 * radius`) elementos de entrada da mem√≥ria global para a mem√≥ria compartilhada.\n",
        "    - üßÆ Calcule `blockDim.x` elementos de sa√≠da.\n",
        "    - ‚úçÔ∏è Escreva `blockDim.x` elementos de sa√≠da na mem√≥ria global.\n",
        "- üåê Cada bloco precisa de um __halo__ de elementos de raio em cada limite.\n",
        "<center>\n",
        "  <img src=\"https://imgur.com/dLs4MeV.png\" alt=\"1dstencil\" width=700 heigh=100>\n",
        "</center>\n",
        "\n",
        "- üìù Segue o c√≥digo do Kernel\n",
        "\n",
        "```cpp\n",
        "__global__ void stencil_1d(int *in, int *out) {\n",
        "  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
        "  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "  // Read input elements into shared memory\n",
        "  temp[lindex] = in[gindex];\n",
        "  if (threadIdx.x < RADIUS) {\n",
        "    temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "  }\n",
        "  \n",
        "  // Apply the stencil\n",
        "  int result = 0;\n",
        "  for (int offset = -RADIUS; offset <= RADIUS; offset++) {\n",
        "    result += temp[lindex + offset];\n",
        "  }\n",
        "\n",
        "  // Store the result\n",
        "  out[gindex] = result;\n",
        "}\n",
        "```\n",
        "<details>\n",
        "<summary>Existe um problema no c√≥digo acima, qual √©?</summary>\n",
        "\n",
        "- üö® Ocorre ***condi√ß√£o de corrida!***\n",
        "- ‚ö°Ô∏è Alguma thread pode tentar ler antes de outra thread ter atualizado a mem√≥ria compartilhada.\n",
        "\n",
        "- ‚úÖ Solu√ßƒÅo: `__syncthreads()`\n",
        " - üß© Sincroniza todas as threads dentro de um bloco.\n",
        " - ‚ö†Ô∏è Usado para evitar riscos de RAW(Read After Write) / WAR(Write After Read) / WAW(Write After Write).\n",
        " - üöß Todas as threads devem chegar √† uma barreira.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "HIcq6zMjHL4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëÄ Segue o c√≥digo completo:"
      ],
      "metadata": {
        "id": "k_dRr2mVbihJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "#define N 8\n",
        "#define BLOCK_SIZE 8\n",
        "#define RADIUS 3\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) {\n",
        "  __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
        "  int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "  // Read input elements into shared memory\n",
        "  temp[lindex] = in[gindex];\n",
        "  if (threadIdx.x < RADIUS) {\n",
        "    temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "    temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "  }\n",
        "  \n",
        "  // Synchronize to make sure all threads have finished reading the data\n",
        "  __syncthreads();\n",
        "\n",
        "  // Apply the stencil\n",
        "  int result = 0;\n",
        "  for (int offset = -RADIUS; offset <= RADIUS; offset++) {\n",
        "    result += temp[lindex + offset];\n",
        "    //printf(\"Thread %d, Bloco %d, Offset %d, temp[%d] = %d\\n\", threadIdx.x, blockIdx.x, offset, lindex + offset, temp[lindex + offset]);\n",
        "  }\n",
        "\n",
        "  // Store the result\n",
        "  out[gindex] = result;\n",
        "  printf(\"Thread %d, Bloco %d, gindex %d, Resultado = %d\\n\", threadIdx.x, blockIdx.x, gindex, result);\n",
        "}\n",
        "\n",
        "void random_ints(int *arr, int num) {\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        arr[i] = arr[i] = 1;//rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_array(const char *name, int *arr, int num) {\n",
        "    std::cout << name << \": \";\n",
        "    for (int i = 0; i < num; ++i) {\n",
        "        std::cout << arr[i] << \" \";\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int *in, *out;\n",
        "    int *d_in, *d_out;\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Alocar espa√ßo para c√≥pias do dispositivo de in e out\n",
        "    cudaMalloc((void **)&d_in, size);\n",
        "    cudaMalloc((void **)&d_out, size);\n",
        "\n",
        "    // Alocar espa√ßo e inicializar c√≥pias do host de in e out\n",
        "    in = (int *)malloc(size);\n",
        "    random_ints(in, N);\n",
        "    out = (int *)malloc(size);\n",
        "\n",
        "    // Copiar entradas para o dispositivo\n",
        "    cudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßar kernel stencil_1d() na GPU\n",
        "    stencil_1d<<<(N + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_in, d_out);\n",
        "\n",
        "    // Copiar resultado de volta para o host\n",
        "    cudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Exibir os vetores in e out no terminal\n",
        "    print_array(\"Vetor de entrada\", in, N);\n",
        "    print_array(\"Vetor de sa√≠da (resultado)\", out, N);\n",
        "\n",
        "    // Limpar\n",
        "    free(in);\n",
        "    free(out);\n",
        "    cudaFree(d_in);\n",
        "    cudaFree(d_out);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGleJdz0XYsA",
        "outputId": "aedc18af-4ebb-41ba-a0fb-8837c9a5bf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0, Bloco 0, gindex 0, Resultado = 4\n",
            "Thread 1, Bloco 0, gindex 1, Resultado = 5\n",
            "Thread 2, Bloco 0, gindex 2, Resultado = 6\n",
            "Thread 3, Bloco 0, gindex 3, Resultado = 7\n",
            "Thread 4, Bloco 0, gindex 4, Resultado = 7\n",
            "Thread 5, Bloco 0, gindex 5, Resultado = 6\n",
            "Thread 6, Bloco 0, gindex 6, Resultado = 5\n",
            "Thread 7, Bloco 0, gindex 7, Resultado = 4\n",
            "Vetor de entrada: 1 1 1 1 1 1 1 1 \n",
            "Vetor de sa√≠da (resultado): 4 5 6 7 7 6 5 4 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üîß Gerenciando o Device\n",
        "---"
      ],
      "metadata": {
        "id": "5ROwlAHejnlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"orange\">**Coordenando Host & Device**</font>\n",
        "\n",
        "- Os lan√ßamentos de kernel s√£o **ass√≠ncronos**\n",
        "    - üîÑ Controle retorna ao CPU imediatamente\n",
        "\n",
        "- O CPU precisa sincronizar antes de consumir os resultados:\n",
        "\n",
        "| Fun√ß√£o              | Descri√ß√£o                                                                   |\n",
        "|---------------------|-----------------------------------------------------------------------------|\n",
        "| `cudaMemcpy()`        | Bloqueia o CPU at√© que a c√≥pia seja conclu√≠da. A c√≥pia come√ßa quando todas as chamadas CUDA anteriores forem conclu√≠das.   |\n",
        "| `cudaMemcpyAsync()`   | Ass√≠ncrono, n√£o bloqueia o CPU                                              |\n",
        "| `cudaDeviceSynchronize()` | Bloqueia o CPU at√© que todas as chamadas CUDA anteriores sejam conclu√≠das |\n",
        "\n",
        "\n",
        "<font color=\"orange\">**Reportando Erros**</font>\n",
        "\n",
        "- Todas as chamadas da API CUDA retornam um c√≥digo de erro (`cudaError_t`)\n",
        "    - ‚ùå Erro na pr√≥pria chamada da API\n",
        "        - OU\n",
        "    - ‚ùå Erro em uma opera√ß√£o ass√≠ncrona anterior (por exemplo, kernel)\n",
        "\n",
        "- Obtenha o c√≥digo de erro do √∫ltimo erro:\n",
        "    - `cudaError_t cudaGetLastError(void)`\n",
        "- Obtenha uma string para descrever o erro:\n",
        "    - `char *cudaGetErrorString(cudaError_t)`\n",
        "\n",
        "```cpp\n",
        "printf(\"%s\\n\", cudaGetErrorString(cudaGetLastError()));\n",
        "```\n",
        "\n",
        "<font color=\"orange\">**Gerenciando o Device**</font>\n",
        "- A aplica√ß√£o pode consultar e selecionar GPUs\n",
        "    - `cudaGetDeviceCount(int *count)`\n",
        "    - `cudaSetDevice(int device)`\n",
        "    - `cudaGetDevice(int *device)`\n",
        "    - `cudaGetDeviceProperties(cudaDeviceProp *prop, int device)`\n",
        "\n",
        "- M√∫ltiplas threads podem compartilhar um dispositivo\n",
        "\n",
        "- Uma √∫nica thread pode gerenciar m√∫ltiplos dispositivos\n",
        "    - `cudaSetDevice(i)` para selecionar o dispositivo atual\n",
        "    - `cudaMemcpy(‚Ä¶)` para c√≥pias ponto a ponto\n"
      ],
      "metadata": {
        "id": "m_JUXoZ8jwNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# T√≥picos Avan√ßados\n",
        "---"
      ],
      "metadata": {
        "id": "eefYUpC6QBsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementa√ßƒÅo de Hardware\n",
        "\n",
        "Dispositivos CUDA cont√™m m√∫ltiplos **Streaming Multiprocessors** (SMs), estes utilizam uma arquitetura de instru√ß√£o √∫nica, m√∫ltiplas threads (**arquitetura SIMT**), com suporte a **multithreading de hardware**.\n",
        "\n",
        "### Streaming Multiprocessors (SMs)\n",
        "\n",
        "- Dispositivo CUDA √© composto por v√°rios SMs.\n",
        "- Cada SM cont√©m um n√∫mero de n√∫cleos CUDA.\n",
        "- Registros e mem√≥ria compartilhados entre os n√∫cleos de cada SM.\n",
        "- Mem√≥ria global maior compartilhada por todos os SMs.\n",
        "- N√∫meros exatos de recursos dependem do hardware espec√≠fico.\n",
        "\n",
        "<center>\n",
        "  <figure>\n",
        "    <img src=\"https://www.researchgate.net/profile/Tianyi-Wang-19/publication/321958738/figure/fig2/AS:627699127160847@1526666542680/Schematic-of-NVIDIA-GPU-architecture-where-SM-refers-to-streaming-multiprocessor_W640.jpg\" alt=\"sms\" width=400 heigh=100>\n",
        "    <figcaption>Fonte: Wang, Tianyi & Kemao, Qian. (2017). GPU Acceleration for Optical Measurement.</figcaption>\n",
        "  </figure>\n",
        "</center>\n",
        "\n",
        "### Arquitetura SIMT (Single-Instruction, Multiple-Thread)\n",
        "\n",
        "A arquitetura SIMT permite que m√∫ltiplas threads executem a mesma instru√ß√£o, mas em diferentes conjuntos de dados, otimizando o processamento paralelo.\n",
        "\n",
        "<center>\n",
        "  <figure>\n",
        "    <img src=\"https://imgur.com/QmyfaP7.png\" alt=\"smit\" width=700 heigh=100>\n",
        "  </figure>\n",
        "</center>\n",
        "\n",
        "#### Vantagens da arquitetura SIMT üòé\n",
        "\n",
        "1. **Efici√™ncia energ√©tica**: Menos energia √© consumida, pois n√£o h√° execu√ß√£o especulativa ou predi√ß√£o de ramifica√ß√£o.\n",
        "2. **Simplicidade de design de hardware**: Sem a necessidade de circuitos complexos para predi√ß√£o de ramifica√ß√£o e buffers para instru√ß√µes especulativas.\n",
        "3. **Maior paralelismo**: A execu√ß√£o de instru√ß√µes em ordem permite que as GPUs mantenham um alto grau de paralelismo.\n",
        "4. **Previsibilidade**: A execu√ß√£o em ordem torna o comportamento da GPU mais previs√≠vel, facilitando a programa√ß√£o e a otimiza√ß√£o de programas.\n",
        "\n",
        "\n",
        "### Hardware Multithreading\n",
        "\n",
        "Quando voc√™ executa um kernel, os blocos s√£o atribu√≠dos aos Multiprocessadores de Streaming (SMs) dispon√≠veis. Geralmente, voc√™ ter√° mais blocos do que pode rodar de uma s√≥ vez, nesse caso, alguns deles v√£o esperar. \n",
        "\n",
        "#### **Divis√£o em Warps** üß©\n",
        "   - Blocos s√£o divididos em warps de 32 threads.\n",
        "   - Os warps s√£o escalonados e executados nos SMs.\n",
        "   - O hardware alterna entre os warps sempre que um precisa esperar.\n",
        "   - O contexto (contadores de programa, registradores, etc.) de cada warp √© mantido no chip durante toda a vida √∫til do warp.\n",
        "   - A mudan√ßa de um contexto de execu√ß√£o para outro n√£o tem custo.\n",
        "\n",
        "#### **Gerenciamento de Recursos de Hardware** üíæ\n",
        "   - O n√∫mero de blocos e warps que podem ser processados depende da quantidade de registradores e mem√≥ria compartilhada dispon√≠veis no multiprocessador.\n",
        "   - Se n√£o houver recursos suficientes para processar pelo menos um bloco, o kernel falha ao ser iniciado.\n",
        "\n",
        "#### **Efici√™ncia** üéØ\n",
        "   - A efici√™ncia na execu√ß√£o de um kernel no CUDA depende em grande parte de como ele gerencia os recursos de hardware.\n"
      ],
      "metadata": {
        "id": "eVh1zPVlQJsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarquia de threadsüßµ\n",
        "\n",
        "### Introdu√ß√£o üéØ\n",
        "As threads podem ser identificadas usando um √≠ndice unidimensional, bidimensional ou tridimensional. Essa organiza√ß√£o fornece uma maneira natural de invocar a computa√ß√£o nos elementos de um dom√≠nio, como um vetor, matriz ou volume.\n",
        "\n",
        "\n",
        "### Exemplo - Adi√ß√£o de Matrizes üìö\n",
        "O seguinte c√≥digo adiciona duas matrizes A e B de tamanho NxN e armazena o resultado na matriz C:\n"
      ],
      "metadata": {
        "id": "vA9PRM6mLbWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 10\n",
        "\n",
        "// Defini√ß√£o do Kernel\n",
        "__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) {\n",
        "    int i = threadIdx.x;\n",
        "    int j = threadIdx.y;\n",
        "    C[i][j] = A[i][j] + B[i][j];\n",
        "    printf(\"Thread [%d][%d]: A[%d][%d] + B[%d][%d] = C[%d][%d]\\n\", i, j, i, j, i, j, i, j);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N], B[N][N], C[N][N];\n",
        "    float (*d_A)[N], (*d_B)[N], (*d_C)[N];\n",
        "\n",
        "    // Aloca√ß√£o de mem√≥ria na GPU\n",
        "    cudaMalloc((void**)&d_A, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_B, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_C, N * N * sizeof(float));\n",
        "\n",
        "    // Inicializa√ß√£o das matrizes A e B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i][j] = i + j;\n",
        "            B[i][j] = i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copia das matrizes A e B para a GPU\n",
        "    cudaMemcpy(d_A, A, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Invoca√ß√£o do Kernel com um bloco de N * N * 1 threads\n",
        "    int numBlocks = 1;\n",
        "    dim3 threadsPerBlock(N, N);\n",
        "    MatAdd<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C);\n",
        "\n",
        "    // Copia da matriz C de volta para a CPU\n",
        "    cudaMemcpy(C, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Impress√£o da matriz C\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%.2f \", C[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Libera√ß√£o da mem√≥ria na GPU\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "1mV05ApnLXKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limita√ß√µes üöß\n",
        "- Todas as threads de um bloco devem residir no mesmo n√∫cleo de multiprocessador de streaming.\n",
        "- As threads devem compartilhar os recursos de mem√≥ria limitados desse n√∫cleo. - Nos GPUs atuais, um bloco de threads pode conter at√© 1024 threads.\n",
        "\n",
        "### __Grid__ de Blocos de Threads üï∏Ô∏è\n",
        "- Os blocos s√£o organizados em um __grid__ unidimensional, bidimensional ou tridimensional de blocos de threads.\n",
        "- O n√∫mero de blocos de threads em um __grid__ √© geralmente ditado pelo tamanho dos dados sendo processados.\n",
        "\n",
        "<center>\n",
        "  <figure>\n",
        "    <img src=\"https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/grid-of-thread-blocks.png\" alt=\"smit\" width=700 heigh=100>\n",
        "        <figcaption>Fonte: https://docs.nvidia.com/cuda/cuda-c-programming-guide.</figcaption>\n",
        "  </figure>\n",
        "</center>\n",
        "\n",
        "### Exemplo - Adi√ß√£o de Matrizes com M√∫ltiplos Blocos üìö"
      ],
      "metadata": {
        "id": "qsf6oGMPHoFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 256\n",
        "\n",
        "// Defini√ß√£o do Kernel\n",
        "__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    \n",
        "    if (i < N && j < N) {\n",
        "        C[i][j] = A[i][j] + B[i][j];\n",
        "        printf(\"Bloco [%d][%d] - Thread [%d][%d]: A[%d][%d] + B[%d][%d] = C[%d][%d]\\n\", blockIdx.x, blockIdx.y, threadIdx.x, threadIdx.y, i, j, i, j, i, j);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float A[N][N], B[N][N], C[N][N];\n",
        "    float (*d_A)[N], (*d_B)[N], (*d_C)[N];\n",
        "\n",
        "    // Aloca√ß√£o de mem√≥ria na GPU\n",
        "    cudaMalloc((void**)&d_A, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_B, N * N * sizeof(float));\n",
        "    cudaMalloc((void**)&d_C, N * N * sizeof(float));\n",
        "\n",
        "    // Inicializa√ß√£o das matrizes A e B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i][j] = i + j;\n",
        "            B[i][j] = i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copia das matrizes A e B para a GPU\n",
        "    cudaMemcpy(d_A, A, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Invoca√ß√£o do Kernel\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1 ) / threadsPerBlock.x, (N + threadsPerBlock.y - 1 )/ threadsPerBlock.y);\n",
        "    MatAdd<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C);\n",
        "\n",
        "    // Copia da matriz C de volta para a CPU\n",
        "    cudaMemcpy(C, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Impress√£o da matriz C\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%.2f \", C[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Libera√ß√£o da mem√≥ria na GPU\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "ul1A7MOmKpu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Exemplo com bloco 3D:"
      ],
      "metadata": {
        "id": "kT0hu2Ephzzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// Macro para verificar erros em chamadas CUDA\n",
        "#define checkCudaErrors(val) check( (val), #val, __FILE__, __LINE__)\n",
        "\n",
        "void check(cudaError_t result, char const *const func, const char *const file, int const line) {\n",
        "    if (result) {\n",
        "        fprintf(stderr, \"CUDA error = %d at %s:%d '%s'\\n\", static_cast<unsigned int>(result), file, line, func);\n",
        "        exit(1);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Defini√ß√£o do Kernel\n",
        "__global__ void InvertVolume(int* volume, int width, int height, int depth) {\n",
        "    // Obtenha os √≠ndices x, y e z\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int z = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    // Verifique se os √≠ndices est√£o dentro do volume\n",
        "    if (x < width && y < height && z < depth) {\n",
        "        // Obtenha o √≠ndice linear a partir dos √≠ndices 3D\n",
        "        int index = x + y * width + z * width * height;\n",
        "\n",
        "        // Inverta o valor no volume\n",
        "        volume[index] = 255 - volume[index];\n",
        "\n",
        "        // Imprima a invers√£o\n",
        "        printf(\"Thread %d, %d, %d invertendo o valor no √≠ndice %d\\n\", threadIdx.x, threadIdx.y, threadIdx.z, index);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Defina o tamanho do volume\n",
        "    int width = 16, height = 16, depth = 16;\n",
        "\n",
        "    // Aloque mem√≥ria para o volume no host\n",
        "    int* volume_host = (int*)malloc(width * height * depth * sizeof(int));\n",
        "\n",
        "    // Aloque mem√≥ria para o volume na GPU\n",
        "    int* volume_device;\n",
        "    checkCudaErrors(cudaMalloc(&volume_device, width * height * depth * sizeof(int)));\n",
        "\n",
        "    // Preencha o volume com valores\n",
        "    for (int i = 0; i < width * height * depth; i++) {\n",
        "        volume_host[i] = i % 256;  // Simplesmente para fins de demonstra√ß√£o\n",
        "    }\n",
        "\n",
        "    // Copie o volume para a GPU\n",
        "    checkCudaErrors(cudaMemcpy(volume_device, volume_host, width * height * depth * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Defina o tamanho dos blocos e da grade\n",
        "    dim3 threadsPerBlock(4, 4, 4);\n",
        "    dim3 numBlocks((width + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                   (height + threadsPerBlock.y - 1) / threadsPerBlock.y,\n",
        "                   (depth + threadsPerBlock.z - 1) / threadsPerBlock.z);\n",
        "\n",
        "    // Invoque o kernel\n",
        "    printf(\"Iniciando o kernel...\\n\");\n",
        "    InvertVolume<<<numBlocks, threadsPerBlock>>>(volume_device, width, height, depth);\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    // Aguarde a conclus√£o do kernel\n",
        "    checkCudaErrors(cudaDeviceSynchronize());\n",
        "    printf(\"Kernel completo.\\n\");\n",
        "\n",
        "    // Copie o volume de volta para o host\n",
        "    checkCudaErrors(cudaMemcpy(volume_host, volume_device, width * height * depth * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Verifique os resultados\n",
        "    for (int i = 0; i < width * height * depth; i++) {\n",
        "        printf(\"Volume na posi√ß√£o %d: %d\\n\", i, volume_host[i]);\n",
        "    }\n",
        "\n",
        "    // Libere a mem√≥ria\n",
        "    free(volume_host);\n",
        "    checkCudaErrors(cudaFree(volume_device));\n",
        "\n",
        "    printf(\"Programa finalizado com sucesso.\\n\");\n",
        "\n",
        "    return 0;\n",
        "}  \n"
      ],
      "metadata": {
        "id": "3fvWB2M8dNcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escolhendo o Tamanho do Bloco em CUDA üí°\n",
        "\n",
        "- Como escolher entre muitos blocos pequenos ou alguns blocos maiores para processar a mesma quantidade de dados?\n",
        "    - A resposta est√°, em grande parte, relacionada ao desempenho.\n",
        "\n",
        "### Ocupa√ß√£o üìä\n",
        "* Primeiro, queremos ter blocos suficientes para manter todos os Multiprocessadores de Streaming (SMs) ocupados. Em termos de CUDA, isso √© chamado de \"ocupa√ß√£o\". \n",
        "* Em geral, quanto maior, melhor, pois permite que o agendador oculte a lat√™ncia do acesso √† mem√≥ria. üöÄ\n",
        "\n",
        "### API de C√°lculo de Ocupa√ß√£o em CUDA üéØ\n",
        "* A CUDA na verdade inclui uma API para calcular o melhor tamanho de bloco para maximizar a ocupa√ß√£o, `cudaOccupancyMaxPotentialBlockSize`. \n",
        "* API de c√°lculo de ocupa√ß√£o, `cudaOccupancyMaxActiveBlocksPerMultiprocessor`, pode fornecer uma previs√£o de ocupa√ß√£o com base no tamanho do bloco e no uso de mem√≥ria compartilhada de um kernel. \n",
        "\n",
        "A seguinte amostra de c√≥digo calcula a ocupa√ß√£o de MyKernel. Em seguida, ele relata o n√≠vel de ocupa√ß√£o com a propor√ß√£o entre warps concorrentes versus o m√°ximo de warps por multiprocessor."
      ],
      "metadata": {
        "id": "xaVCLE5NKqUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "\n",
        "// C√≥digo do dispositivo\n",
        "__global__ void MyKernel(int *d, int *a, int *b)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    d[idx] = a[idx] * b[idx];\n",
        "}\n",
        "\n",
        "// C√≥digo do host\n",
        "int main()\n",
        "{\n",
        "    int numBlocks;        // Ocupa√ß√£o em termos de blocos ativos\n",
        "    int blockSize = 64;\n",
        "\n",
        "    // Estas vari√°veis s√£o usadas para converter a ocupa√ß√£o em warps\n",
        "    int device;\n",
        "    cudaDeviceProp prop;\n",
        "    int activeWarps;\n",
        "    int maxWarps;\n",
        "\n",
        "    cudaGetDevice(&device);\n",
        "    cudaGetDeviceProperties(&prop, device);\n",
        "\n",
        "    cudaOccupancyMaxActiveBlocksPerMultiprocessor(\n",
        "        &numBlocks,\n",
        "        MyKernel,\n",
        "        blockSize,\n",
        "        0);\n",
        "\n",
        "    activeWarps = numBlocks * blockSize / prop.warpSize;\n",
        "    maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n",
        "\n",
        "    std::cout << \"N√∫mero de blocos ativos: \" << numBlocks << std::endl;\n",
        "    std::cout << \"Tamanho do bloco: \" << blockSize << std::endl;\n",
        "    std::cout << \"N√∫mero de warps ativos: \" << activeWarps << std::endl;\n",
        "    std::cout << \"N√∫mero m√°ximo de warps por multiprocessador: \" << maxWarps << std::endl;\n",
        "    std::cout << \"Ocupa√ß√£o: \" << (double)activeWarps / maxWarps * 100 << \"%\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6NRKXmezs2i",
        "outputId": "bbe681c0-9e7b-4341-c938-38f1420c74d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de blocos ativos: 16\n",
            "Tamanho do bloco: 64\n",
            "N√∫mero de warps ativos: 32\n",
            "N√∫mero m√°ximo de warps por multiprocessador: 32\n",
            "Ocupa√ß√£o: 100%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguinte amostra de c√≥digo configura um lan√ßamento de kernel baseado em ocupa√ß√£o do MyKernel de acordo com a entrada do usu√°rio."
      ],
      "metadata": {
        "id": "6naqMLvO4-32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<iostream>\n",
        "#include <iostream>\n",
        "\n",
        "// C√≥digo do dispositivo\n",
        "__global__ void MyKernel(int *array, int arrayCount)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < arrayCount) {\n",
        "        array[idx] *= array[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// C√≥digo do host\n",
        "int launchMyKernel(int *array, int arrayCount)\n",
        "{\n",
        "    int blockSize;\n",
        "    int minGridSize;\n",
        "    int gridSize;\n",
        "\n",
        "    cudaOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, (void *)MyKernel, 0, arrayCount);\n",
        "\n",
        "    gridSize = (arrayCount + blockSize - 1) / blockSize;\n",
        "\n",
        "    std::cout << \"Tamanho do bloco: \" << blockSize << std::endl;\n",
        "    std::cout << \"Quantidade m√≠nima de blocos: \" << minGridSize << std::endl;// quantidade minimoa para obter a ocupa√ß√£o m√°xima no dispositivo\n",
        "    std::cout << \"Quantidade de  Blocos: \" << gridSize << std::endl;\n",
        "\n",
        "    MyKernel<<<gridSize, blockSize>>>(array, arrayCount);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int arrayCount = 10000;\n",
        "    int *array;\n",
        "\n",
        "    //Alocar mem√≥ria que pode ser acessada de maneira unificada\n",
        "    // tanto pelo host (CPU) quanto pelo dispositivo (GPU).\n",
        "    cudaMallocManaged(&array, arrayCount * sizeof(int));\n",
        "    for (int i = 0; i < arrayCount; i++) {\n",
        "        array[i] = i;\n",
        "    }\n",
        "\n",
        "    // Chame a fun√ß√£o launchMyKernel\n",
        "    launchMyKernel(array, arrayCount);\n",
        "\n",
        "    // Sincronize o dispositivo e libere a mem√≥ria\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaFree(array);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4S1kJ244_rX",
        "outputId": "130cfd1e-a973-4dab-acb5-da8b8c0647c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do bloco: 1024\n",
            "Quantidade m√≠nima de blocos: 40\n",
            "Quantidade de  Blocos: 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sincroniza√ß√£o e Comunica√ß√£o üîÅ\n",
        "* Se estamos sincronizando ou comunicando entre as threads em um bloco, o que exploraremos em uma se√ß√£o posterior, ent√£o o tamanho do bloco ter√° um grande impacto.\n",
        "\n",
        "### Diretrizes B√°sicas üìù\n",
        "Para come√ßar, aqui est√£o algumas diretrizes b√°sicas:\n",
        "* **Independ√™ncia dos Blocos de Threads**: Os blocos de threads devem ser executados de forma independente, ou seja, deve ser poss√≠vel execut√°-los em qualquer ordem, em paralelo ou em s√©rie. Isso permite que os programadores escrevam c√≥digo que seja escal√°vel com o n√∫mero de n√∫cleos. \n",
        "* **Escalonamento de Threads e Warps**: CUDA sempre agenda threads e warps de 32, ent√£o o tamanho do bloco deve ser um m√∫ltiplo disso para evitar a cria√ß√£o de warps parcialmente vazios. 128 ou 256 geralmente √© um bom ponto de partida. \n",
        "* **Mais Blocos do que SMs**: Geralmente queremos mais blocos do que existem SMs. Se tivermos menos, alguns SMs ficar√£o ociosos. Muitas vezes √© bom ter v√°rios blocos menores ativos para que o agendador possa troc√°-los se precisarem esperar pelo acesso √† mem√≥ria. \n",
        "\n",
        "### Teste e Medi√ß√£o üìèüìê\n",
        "* No entanto, estas s√£o apenas diretrizes. Se voc√™ est√° tentando obter o m√°ximo desempenho de seus kernels, sempre deve experimentar diferentes configura√ß√µes e medir os resultados. üéØ\n",
        "\n",
        "***Portanto, na busca pelo desempenho ideal, lembre-se de experimentar e medir! üöÄ***\n"
      ],
      "metadata": {
        "id": "cpReV39O0W9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ Diretrizes de Desempenho \n",
        "A otimiza√ß√£o de desempenho gira em torno de quatro estrat√©gias b√°sicas:\n",
        "\n",
        "1. **Maximizar a execu√ß√£o paralela** para alcan√ßar a m√°xima utiliza√ß√£o;\n",
        " - Aqui usamos as fun√ß√µes do CUDA para melhorar a ocupa√ßƒÅo.\n",
        "2. **Otimizar o uso de mem√≥ria** para alcan√ßar a m√°xima largura de banda de mem√≥ria;\n",
        "3. **Otimizar o uso de instru√ß√µes** para alcan√ßar a m√°xima largura de banda de instru√ß√µes;\n",
        "4. **Minimizar a thrashing de mem√≥ria**.\n",
        "\n",
        "## Uso de Eficiente de Mem√≥ria\n",
        "\n",
        "***Hierarquia de Mem√≥ria***\n",
        "1. Mem√≥ria global: Grande e de alta lat√™ncia.\n",
        "1. Cache L2: Lat√™ncia m√©dia.\n",
        "1. Caches SM: Lat√™ncia baixa.\n",
        "1. Registradores: lat√™ncia m√≠minima.\n",
        "\n",
        "<center>\n",
        "  <figure>\n",
        "    <img src=\"https://imgur.com/MPzJBeD.png\" alt=\"smit\" width=500 heigh=100>\n",
        "  </figure>\n",
        "</center>\n",
        "\n",
        "## Mitigando a Lat√™ncia da Mem√≥ria Global üïìüîÅ\n",
        "Existem algumas t√©cnicas que CUDA usa para mitigar essa lat√™ncia:\n",
        "\n",
        "1. **Cache L2**: Este cache √© compartilhado por todos os SMs e, embora tenha menor lat√™ncia que a mem√≥ria global, ainda √© muito mais lento que os registradores locais a cada SM. Al√©m disso, √© bastante pequeno, geralmente apenas alguns megabytes no m√°ximo.\n",
        "\n",
        "2. **Troca de Warps**: Quando um warp est√° esperando pela mem√≥ria, o runtime do CUDA pode trocar outro warp e continuar trabalhando. √â por isso que a alta ocupa√ß√£o √© importante, pois permite que o programador oculte parte dessa lat√™ncia de mem√≥ria.\n",
        "\n",
        "3. **Coalesc√™ncia de Mem√≥ria**: Quando os threads em um warp fazem cargas ou armazenamentos adjacentes, o CUDA pode coalescer essas opera√ß√µes em uma √∫nica transa√ß√£o de mem√≥ria. Isso aumenta a taxa de transfer√™ncia e reduz a quantidade de tempo que o warp tem que esperar.\n",
        "\n",
        "## Coalesc√™ncia de Mem√≥ria üìêüßÆ\n",
        "\n",
        "- As instru√ß√µes de mem√≥ria global suportam a leitura ou escrita de palavras de tamanho igual a 1, 2, 4, 8 ou 16 bytes. üóÇÔ∏èüíª\n",
        "\n",
        "<center>\n",
        "  <figure>\n",
        "    <img src=\"https://imgur.com/uyKtRjE.png\" alt=\"smit\" width=500 heigh=100>\n",
        "  </figure>\n",
        "</center>\n",
        "  \n",
        "- Para estruturas, os requisitos de tamanho e alinhamento podem ser for√ßados pelo compilador usando os especificadores de alinhamento __align__(8) ou __align__(16), como:\n",
        "\n",
        "```c++\n",
        "struct __align__(8) {\n",
        "    float x;\n",
        "    float y;\n",
        "};\n",
        "```\n",
        "ou\n",
        "```c++\n",
        "struct __align__(16) {\n",
        "    float x;\n",
        "    float y;\n",
        "    float z;\n",
        "};\n",
        "```\n",
        "\n",
        "## Arrays Bidimensionais üååüéØ\n",
        "\n",
        "- Um padr√£o comum de acesso √† mem√≥ria global √©:\n",
        "```c++\n",
        "BaseAddress + width * ty + tx\n",
        "```\n",
        "- Para que esses acessos sejam totalmente coalescidos, tanto a largura do bloco de threads quanto a largura do array devem ser m√∫ltiplos do tamanho do warp. ‚è´üîÄ\n",
        "\n",
        "- Por exemplo, se temos um array 2D de 3x3:\n",
        "\n",
        "```\n",
        "1 2 3\n",
        "4 5 6\n",
        "7 8 9\n",
        "```\n",
        "\n",
        "- Para acessar o elemento '5', que est√° na posi√ß√£o (1, 1), voc√™ faria: `BaseAddress + 3 * 1 + 1`.\n",
        "\n",
        "- As fun√ß√µes `cudaMallocPitch()`, `cuMemAllocPitch()` e `cudaMemcpy2Das` permitem alocar arrays que se conformam as restri√ß√µes de alinhamento e tamanho adequadas\n"
      ],
      "metadata": {
        "id": "PHctYxVvTPrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdint>\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <curand.h>\n",
        "\n",
        "//Exemplo demonstrativo de uso de alinhamento de mem√≥ria\n",
        "\n",
        "// Estrutura de pixel\n",
        "struct __align__(16) pixel {\n",
        "  float red;\n",
        "  float green;\n",
        "  float blue;\n",
        "  float alpha;\n",
        "};\n",
        "\n",
        "// Par√¢metros do teste\n",
        "struct test_params {\n",
        "  unsigned int width;\n",
        "  unsigned int height;\n",
        "  pixel *input_image;\n",
        "  pixel *output_image;\n",
        "};\n",
        "\n",
        "__global__ void monochrome(const pixel *source, pixel *dest, int size) {\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (index >= size) return;\n",
        "\n",
        "  float value(source[index].red * 0.3125f + source[index].green * 0.5f +\n",
        "              source[index].blue * .1875f);\n",
        "\n",
        "  dest[index].red = value;\n",
        "  dest[index].green = value;\n",
        "  dest[index].blue = value;\n",
        "  dest[index].alpha = source[index].alpha;\n",
        "}\n",
        "\n",
        "// Configurar teste com uma imagem aleat√≥ria\n",
        "test_params set_up_test(unsigned int width, unsigned int height) {\n",
        "  test_params params;\n",
        "  params.width = width;\n",
        "  params.height = height;\n",
        "\n",
        "  // Alocar mem√≥ria para a imagem de entrada e sa√≠da\n",
        "  size_t image_size = params.width * params.height * sizeof(pixel);\n",
        "  pixel *host_image = (pixel*) malloc(image_size);\n",
        "  cudaMalloc(&params.input_image, image_size);\n",
        "  cudaMalloc(&params.output_image, image_size);\n",
        "\n",
        "  // Gerar uma imagem de entrada aleat√≥ria no host\n",
        "  for(int i = 0; i < params.width * params.height; i++) {\n",
        "      host_image[i].red = (float)rand() / RAND_MAX;\n",
        "      host_image[i].green = (float)rand() / RAND_MAX;\n",
        "      host_image[i].blue = (float)rand() / RAND_MAX;\n",
        "      host_image[i].alpha = (float)rand() / RAND_MAX;\n",
        "  }\n",
        "\n",
        "  // Transferir a imagem do host para o device\n",
        "  cudaMemcpy(params.input_image, host_image, image_size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  free(host_image);\n",
        "\n",
        "  return params;\n",
        "}\n",
        "\n",
        "// Limpar ap√≥s o teste\n",
        "void finish_test(test_params params) {\n",
        "  cudaFree(params.input_image);\n",
        "  cudaFree(params.output_image);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  unsigned int width = 2048; // Largura da imagem\n",
        "  unsigned int height = 2048; // Altura da imagem\n",
        "\n",
        "  test_params params = set_up_test(width, height);\n",
        "\n",
        "  int pixel_count = params.width * params.height;\n",
        "  int BLOCK_SIZE = 128;\n",
        "  int n_blocks = (pixel_count + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "  // Criar eventos para medir o tempo\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // Registrar o in√≠cio do evento\n",
        "  cudaEventRecord(start);\n",
        "  \n",
        "  monochrome<<<n_blocks, BLOCK_SIZE>>>(params.input_image, params.output_image, pixel_count);\n",
        "  \n",
        "  // Registrar o fim do evento\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  // Sincronizar, para garantir que o evento de parada ocorreu\n",
        "  cudaEventSynchronize(stop);\n",
        "\n",
        "  float milliseconds = 0;\n",
        "\n",
        "  // Calcular o tempo decorrido em milissegundos\n",
        "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "  std::cout << \"O tempo de execu√ß√£o do kernel em milissegundos foi: \" << milliseconds << std::endl;\n",
        "\n",
        "  finish_test(params);\n",
        "\n",
        "  // Limpar eventos\n",
        "  cudaEventDestroy(start);\n",
        "  cudaEventDestroy(stop);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXWt9nYPiWKd",
        "outputId": "5eac00f8-5557-4154-e51f-b657d5ecb8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O tempo de execu√ß√£o do kernel em milissegundos foi: 0.572224\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mem√≥ria Constante\n",
        "\n",
        "* Mem√≥ria otimizada para situa√ß√µes em que todos os threads de um warp l√™em o mesmo local de mem√≥ria ao mesmo tempo.\n",
        "    * Quando isso ocorre, a leitura √© transmitida para todos os threads, o que √© mais r√°pido do que se cada thread tivesse que ler um local de mem√≥ria separado.\n",
        "\n",
        "* A mem√≥ria constante √© limitada a 64 KB. Para usar a mem√≥ria constante, voc√™ deve declarar a vari√°vel com o qualificador `__constant__`.\n",
        "\n",
        "* Primeiro, vamos olhar para um exemplo de c√≥digo CUDA que processa imagens sem utilizar a mem√≥ria constante."
      ],
      "metadata": {
        "id": "jzB3sJt3q5ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdint>\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <curand.h>\n",
        "#include <ctime>\n",
        "\n",
        "// Estrutura de pixel\n",
        "struct __align__(16) pixel {\n",
        "  float red;\n",
        "  float green;\n",
        "  float blue;\n",
        "  float alpha;\n",
        "};\n",
        "\n",
        "// Kernel\n",
        "__global__ void process_image(pixel *img, int img_size, pixel* filter, int filter_size) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index >= img_size) return;\n",
        "\n",
        "    pixel result = {0, 0, 0, 0};\n",
        "\n",
        "    // Aplicar o filtro na imagem\n",
        "    for(int i = 0; i < filter_size; i++) {\n",
        "        result.red += img[index + i].red * filter[i].red;\n",
        "        result.green += img[index + i].green * filter[i].green;\n",
        "        result.blue += img[index + i].blue * filter[i].blue;\n",
        "    }\n",
        "\n",
        "    img[index] = result;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int img_size = 8192 * 8192;\n",
        "    const int filter_size = 1024;\n",
        "\n",
        "    // Aloca√ß√£o de mem√≥ria para imagem e filtro\n",
        "    pixel *d_img, *d_filter;\n",
        "    cudaMalloc(&d_img, img_size * sizeof(pixel));\n",
        "    cudaMalloc(&d_filter, filter_size * sizeof(pixel));\n",
        "\n",
        "    // Inicializa√ß√£o do filtro\n",
        "    pixel h_filter[filter_size];\n",
        "    for(int i = 0; i < filter_size; i++) {\n",
        "        h_filter[i] = {0.1, 0.1, 0.1, 0};\n",
        "    }\n",
        "    cudaMemcpy(d_filter, h_filter, filter_size * sizeof(pixel), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Lan√ßamento do kernel\n",
        "    clock_t start = clock();\n",
        "    process_image<<<img_size/256, 256>>>(d_img, img_size, d_filter, filter_size);\n",
        "    cudaDeviceSynchronize();\n",
        "    clock_t end = clock();\n",
        "    \n",
        "    double time = ((double) (end - start)) / CLOCKS_PER_SEC * 1000;\n",
        "    printf(\"Tempo de execu√ß√£o sem mem√≥ria constante: %f milisegundos\\n\", time);\n",
        "\n",
        "    cudaFree(d_img);\n",
        "    cudaFree(d_filter);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhn_I5ifsVnv",
        "outputId": "d8c78e56-f246-4ebf-ba1e-cd44243612d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execu√ß√£o sem mem√≥ria constante: 784.807000 milisegundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos modificar este c√≥digo para utilizar a mem√≥ria constante para o filtro. A mem√≥ria constante √© √∫til quando temos dados que s√£o lidos muitas vezes por muitas threads, como √© o caso do nosso filtro."
      ],
      "metadata": {
        "id": "pUZaPKhTtD7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdint>\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <curand.h>\n",
        "#include <ctime>\n",
        "\n",
        "// Estrutura de pixel\n",
        "struct __align__(16) pixel {\n",
        "  float red;\n",
        "  float green;\n",
        "  float blue;\n",
        "  float alpha;\n",
        "};\n",
        "\n",
        "__constant__ pixel c_filter[1024];\n",
        "\n",
        "// Kernel\n",
        "__global__ void process_image(pixel *img, int img_size) {\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (index >= img_size) return;\n",
        "\n",
        "    pixel result = {0, 0, 0, 0};\n",
        "\n",
        "    // Aplicar o filtro na imagem\n",
        "    for(int i = 0; i < 1024; i++) {\n",
        "        result.red += img[index + i].red * c_filter[i].red;\n",
        "        result.green += img[index + i].green * c_filter[i].green;\n",
        "        result.blue += img[index + i].blue * c_filter[i].blue;\n",
        "    }\n",
        "\n",
        "    img[index] = result;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int img_size = 8192 * 8192;\n",
        "    const int filter_size = 1024;\n",
        "\n",
        "    // Aloca√ß√£o de mem√≥ria para imagem\n",
        "    pixel *d_img;\n",
        "    cudaMalloc(&d_img, img_size * sizeof(pixel));\n",
        "\n",
        "    // Inicializa√ß√£o do filtro\n",
        "    pixel h_filter[filter_size];\n",
        "    for(int i = 0; i < filter_size; i++) {\n",
        "        h_filter[i] = {0.1, 0.1, 0.1, 0};\n",
        "    }\n",
        "    cudaMemcpyToSymbol(c_filter, h_filter, filter_size * sizeof(pixel));\n",
        "\n",
        "    // Lan√ßamento do kernel\n",
        "    clock_t start = clock();\n",
        "    process_image<<<img_size/256, 256>>>(d_img, img_size);\n",
        "    cudaDeviceSynchronize();\n",
        "    clock_t end = clock();\n",
        "    \n",
        "    double time = ((double) (end - start)) / CLOCKS_PER_SEC * 1000;\n",
        "    printf(\"Tempo de execu√ß√£o com mem√≥ria constante: %f milisegundos\\n\", time);\n",
        "\n",
        "    cudaFree(d_img);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs91MDVktDao",
        "outputId": "50e9fdd9-c009-400e-a424-15a1f7fc28ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execu√ß√£o com mem√≥ria constante: 535.173000 milisegundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1F6ToelPtDFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mem√≥ria de Textura \n",
        "\n",
        "* A mem√≥ria de textura √© otimizada para esses padr√µes de acesso espacialmente localizados. \n",
        "    - Ela √© projetada para ser usada quando os threads acessam a mem√≥ria em um padr√£o de \"vizinhan√ßa\". \n",
        "\n",
        "* Al√©m disso, a mem√≥ria de textura possui recursos adicionais para lidar com texturas, como a capacidade de fazer interpola√ß√£o de valores automaticamente.\n",
        "\n",
        "* Para usar a mem√≥ria de textura, voc√™ deve declarar o array como um `cudaArray` ou um `cudaTextureObject_t` e usar fun√ß√µes de acesso espec√≠ficas.\n",
        "\n",
        "* vamos para um exemplo sem mem√≥ria de textura e depois comparar com o uso da mem√≥ria.\n"
      ],
      "metadata": {
        "id": "KzfrsAyDsT2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define WIDTH 8192\n",
        "#define HEIGHT 8192\n",
        "#define FILTER_SIZE 5\n",
        "\n",
        "// Estrutura de pixel\n",
        "struct pixel {\n",
        "  float red;\n",
        "  float green;\n",
        "  float blue;\n",
        "  float alpha;\n",
        "};\n",
        "\n",
        "// Kernel\n",
        "__global__ void process_image(pixel *img) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int index = y * WIDTH + x;\n",
        "    \n",
        "    if (x >= WIDTH || y >= HEIGHT) return;\n",
        "    \n",
        "    pixel result = {0, 0, 0, 0};\n",
        "\n",
        "    // Aplicar o filtro na imagem\n",
        "    for(int i = -FILTER_SIZE / 2; i <= FILTER_SIZE / 2; i++) {\n",
        "        for(int j = -FILTER_SIZE / 2; j <= FILTER_SIZE / 2; j++) {\n",
        "            int cur_x = min(max(x + i, 0), WIDTH - 1);\n",
        "            int cur_y = min(max(y + j, 0), HEIGHT - 1);\n",
        "            pixel cur_pixel = img[cur_y * WIDTH + cur_x];\n",
        "            result.red += cur_pixel.red;\n",
        "            result.green += cur_pixel.green;\n",
        "            result.blue += cur_pixel.blue;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    result.red /= (FILTER_SIZE * FILTER_SIZE);\n",
        "    result.green /= (FILTER_SIZE * FILTER_SIZE);\n",
        "    result.blue /= (FILTER_SIZE * FILTER_SIZE);\n",
        "\n",
        "    img[index] = result;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 block_size(16, 16);\n",
        "    dim3 grid_size((WIDTH + block_size.x - 1) / block_size.x, (HEIGHT + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Aloca√ß√£o de mem√≥ria para imagem\n",
        "    pixel *d_img;\n",
        "    cudaMalloc(&d_img, WIDTH * HEIGHT * sizeof(pixel));\n",
        "\n",
        "    // Lan√ßamento do kernel\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    process_image<<<grid_size, block_size>>>(d_img);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Tempo de execu√ß√£o sem mem√≥ria de textura: %f milisegundos\\n\", milliseconds);\n",
        "\n",
        "    cudaFree(d_img);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEb4JB623pT_",
        "outputId": "4377ad3a-95d8-4ca1-803e-a41ab70bd810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execu√ß√£o sem mem√≥ria de textura: 68.442116 milisegundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com mem√≥ria de textura:"
      ],
      "metadata": {
        "id": "uirXNvsJ3p3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define WIDTH 8192\n",
        "#define HEIGHT 8192\n",
        "\n",
        "texture<float, 2, cudaReadModeElementType> tex;\n",
        "\n",
        "__global__ void filter(float *output, int width, int height) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (x < width && y < height) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        // Aplicar filtro de 5x5\n",
        "        for (int i = -2; i <= 2; ++i) {\n",
        "            for (int j = -2; j <= 2; ++j) {\n",
        "                sum += tex2D(tex, x + i, y + j);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[y * width + x] = sum / 25.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Alocar e inicializar uma imagem na mem√≥ria do host\n",
        "    float *h_img = new float[WIDTH * HEIGHT];\n",
        "    for (int i = 0; i < WIDTH * HEIGHT; ++i) {\n",
        "        h_img[i] = static_cast<float>(i);\n",
        "    }\n",
        "\n",
        "    // Alocar mem√≥ria na GPU e copiar a imagem para ela\n",
        "    float *d_img;\n",
        "    cudaMalloc(&d_img, WIDTH * HEIGHT * sizeof(float));\n",
        "    cudaMemcpy(d_img, h_img, WIDTH * HEIGHT * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configurar a textura\n",
        "    tex.addressMode[0] = cudaAddressModeClamp;\n",
        "    tex.addressMode[1] = cudaAddressModeClamp;\n",
        "    tex.channelDesc = cudaCreateChannelDesc<float>();\n",
        "    cudaBindTexture2D(0, tex, d_img, WIDTH, HEIGHT, WIDTH * sizeof(float));\n",
        "\n",
        "    // Alocar mem√≥ria na GPU para a imagem filtrada\n",
        "    float *d_output;\n",
        "    cudaMalloc(&d_output, WIDTH * HEIGHT * sizeof(float));\n",
        "\n",
        "    // Configurar a grade e os blocos\n",
        "    dim3 block_size(16, 16);\n",
        "    dim3 grid_size((WIDTH + block_size.x - 1) / block_size.x, (HEIGHT + block_size.y - 1) / block_size.y);\n",
        "\n",
        "    // Criar eventos para medi√ß√£o do tempo\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Iniciar a medi√ß√£o do tempo\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Aplicar o filtro\n",
        "    filter<<<grid_size, block_size>>>(d_output, WIDTH, HEIGHT);\n",
        "\n",
        "    // Parar a medi√ß√£o do tempo\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    // Sincronizar\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Obter o tempo decorrido\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"Tempo de execu√ß√£o do kernel: \" << milliseconds << \" milissegundos\\n\";\n",
        "\n",
        "    // Copiar a imagem filtrada de volta para a mem√≥ria do host\n",
        "    cudaMemcpy(h_img, d_output, WIDTH * HEIGHT * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Libere a mem√≥ria\n",
        "    cudaFree(d_img);\n",
        "    cudaFree(d_output);\n",
        "    delete[] h_img;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbz0Enf73qTq",
        "outputId": "2d1e0461-ff12-4269-c717-08b68851a6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de execu√ß√£o do kernel: 18.2383 milissegundos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Otimizar o uso de instru√ß√µes \n",
        "**1. Otimiza√ß√µes de Instru√ß√µes e Fluxo de Controle**\n",
        "\n",
        "Esta √© uma tarefa cont√≠nua durante o desenvolvimento do programa, mas uma coisa espec√≠fica que voc√™ pode fazer √© garantir que suas threads estejam acessando a mem√≥ria de uma maneira ideal. Por exemplo, para garantir que as threads estejam acessando a mem√≥ria de forma coalescente.\n",
        "\n",
        "**2. Tipos Vetoriais**\n",
        "\n",
        "Os tipos vetoriais podem ser usados para leituras e grava√ß√µes mais amplas na mem√≥ria. Aqui est√° um exemplo de c√≥digo usando o tipo vetor `float4`:\n",
        "\n",
        "```C\n",
        "__global__ void kernel(float4 *a, int N)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N)\n",
        "    {\n",
        "        float4 f4 = a[idx];\n",
        "        f4.x += f4.y + f4.z + f4.w;\n",
        "        a[idx] = f4;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "**3. Paralelismo a N√≠vel de Instru√ß√£o**\n",
        "\n",
        "Para aumentar o paralelismo a n√≠vel de instru√ß√£o, voc√™ pode calcular m√∫ltiplos resultados independentes em cada thread:\n",
        "\n",
        "```C\n",
        "__global__ void kernel(float *a, float *b, int N)\n",
        "{\n",
        "    int idx = (threadIdx.x + blockIdx.x * blockDim.x) * 2;\n",
        "    if (idx < N)\n",
        "    {\n",
        "        a[idx] = sinf(b[idx]);\n",
        "        a[idx + 1] = cosf(b[idx + 1]);\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "**4. Diverg√™ncia de Warp**\n",
        "\n",
        "Aqui est√° um exemplo de c√≥digo que cria diverg√™ncia de warp, o que deve ser evitado:\n",
        "\n",
        "```C\n",
        "__global__ void kernel(int *a, int N)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N)\n",
        "    {\n",
        "        if (idx % 2 == 0)\n",
        "            a[idx] = idx;\n",
        "        else\n",
        "            a[idx] = -idx;\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "**5. Fun√ß√µes Intr√≠nsecas**\n",
        "\n",
        "As fun√ß√µes intr√≠nsecas podem ser usadas para opera√ß√µes matem√°ticas mais r√°pidas. Aqui est√° um exemplo usando a fun√ß√£o intr√≠nseca `__fadd_rn`:\n",
        "\n",
        "```C\n",
        "__global__ void kernel(float *a, float *b, int N)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N)\n",
        "        a[idx] = __fadd_rn(a[idx], b[idx]);\n",
        "}\n",
        "```\n",
        "- A fun√ß√£o `__fadd_rn` √© uma fun√ß√£o intr√≠nseca do CUDA que realiza uma adi√ß√£o de ponto flutuante em precis√£o simples. \n",
        "- Tamb√©m h√° uma flag, chamada de `--use_fast_math` que pode ser usada durante a compila√ßƒÅo para substituir todos as fun√ß√µes com seu equivalente mais r√°pido em CUDA.\n",
        "- Lembre-se, esses s√£o apenas exemplos simplificados e o uso real dessas t√©cnicas depender√° do problema espec√≠fico que voc√™ est√° tentando resolver."
      ],
      "metadata": {
        "id": "o942s8GRYRr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Plataforma CUDA\n",
        "---"
      ],
      "metadata": {
        "id": "nmmnn5ouy6Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- <center>\n",
        "Plataforma de Computa√ß√£o Paralela CUDA\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/zNxIQLD.png\" alt=\"smit\" width=700 heigh=100>\n",
        "        <figcaption>Fonte: https://developer.nvidia.com/cuda-education-training </figcaption>\n",
        "</figure>\n",
        "</center>\n",
        "-->\n",
        "H√° tr√™s maneiras de acelerar aplica√ß√µes em CUDA:\n",
        "<center>\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/JoRjCPV.png\" alt=\"smit\" width=500 heigh=100>\n",
        "        <figcaption>Fonte: https://developer.nvidia.com/cuda-education-training </figcaption>\n",
        "</figure>\n",
        "</center>\n",
        "\n",
        "## ***Bibliotecas***\n",
        "\n",
        "- üòÉ **Facilidade de uso**:  Usar bibliotecas permite a acelera√ß√£o de GPU sem conhecimento profundo de programa√ß√£o de GPU.\n",
        "\n",
        "- üîÑ **\"Drop-in\"**: Muitas bibliotecas aceleradas por GPU seguem APIs padr√£o, para uma ampla gama de aplica√ß√µes.\n",
        "\n",
        "- üí™ **Desempenho**: As bibliotecas da NVIDIA s√£o refinadas por especialistas da NVIDIA.\n",
        "\n",
        "<center>\n",
        "Algumas bibliotecas CUDA\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/joAE9DT.png\" alt=\"smit\" width=500 heigh=100>\n",
        "        <figcaption>Fonte: https://developer.nvidia.com/cuda-education-training </figcaption>\n",
        "</figure>\n",
        "</center>\n",
        "\n",
        "- ***Sinal, video e imagem***: NVIDIA 2D Image And Signal Performance Primitives (NPP), cuFFT e video Codec SDK.\n",
        "- ***√Ålgebra linear e matem√°tica***: cuBLAS, cuSPARSE, cuRAND e  CUSP. \n",
        "- ***Algoritmos paralelos***: Thurst."
      ],
      "metadata": {
        "id": "SJPrmdiXzHeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Diretivas OpenACC\n",
        "\n",
        "O OpenACC √© uma diretiva de programa√ß√£o de alto n√≠vel projetada para simplificar a programa√ß√£o paralela em GPU. \n",
        "\n",
        "**Pontos fortes**:\n",
        "\n",
        "1. **Simplicidade**: üòá O OpenACC utiliza diretivas, o que significa que √© poss√≠vel paralelizar seu c√≥digo sem ter que escrever explicitamente o c√≥digo de baixo n√≠vel para a GPU.\n",
        "\n",
        "2. **Portabilidade**: üåé As diretivas OpenACC s√£o projetadas para serem port√°veis entre diferentes tipos de dispositivos e plataformas. Isso significa que o mesmo c√≥digo pode ser executado tanto em CPUs quanto em GPUs.\n",
        "\n",
        "3. **Performance**: üöÄ O OpenACC permite que os desenvolvedores aproveitem a pot√™ncia de processamento paralelo das GPUs, sem a necessidade de ser um especialista em GPU.\n",
        "\n",
        "**C√≥digo Demonstrativo**:\n",
        "\n",
        "```c\n",
        "#pragma acc data copyin(A[0:n], B[0:n]) copyout(C[0:n])\n",
        "{\n",
        "    #pragma acc kernels\n",
        "    {\n",
        "        for(int i = 0; i < n; i++){\n",
        "            C[i] = A[i] + B[i];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "- Este c√≥digo √© um exemplo simples de como adicionar diretivas OpenACC a um loop de soma de vetor para execut√°-lo em uma GPU.\n",
        "- Mais informa√ß√µes: [openACC](https://www.openacc.org/)\n"
      ],
      "metadata": {
        "id": "eF6Rd_aBgnzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linguagens de Programa√ß√£o para GPU \n",
        "\n",
        "Existem v√°rias linguagens que podem ser usadas para programa√ß√£o de GPU, cada uma com suas pr√≥prias caracter√≠sticas e vantagens.\n",
        "\n",
        "- **An√°lise num√©rica**: MATLAB, Mathematica, LabVIEW\n",
        "- **Fortran**: OpenACC, CUDA Fortran\n",
        "- **C/C++**: OpenACC, CUDA C\n",
        "- **C++**: Thrust, CUDA C++\n",
        "- **Python**: PyCUDA, Numba, CuPy, CUDA Python.\n",
        "- **F#**: Alea.cuBase\n"
      ],
      "metadata": {
        "id": "8V-N24Adgrw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programa√ß√£o CUDA em Python üêçüöÄ\n",
        "\n",
        "Vamos introduzir quatro pacotes  para programa√ß√£o CUDA em Python: Numba, PyCUDA, CuPy e CUDA Python. Cada um deles oferece uma abordagem √∫nica para aproveitar o poder das GPUs diretamente do Python."
      ],
      "metadata": {
        "id": "CodA3g6qdDif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Numba** üêÜ\n",
        "\n",
        "\n",
        "<font color=\"orange\">***O que √©***</font>\n",
        "\n",
        "Numba √© uma biblioteca de compilador JIT (*Just-In-Time*) que traduz um subconjunto de Python e NumPy diretamente em c√≥digo de m√°quina via LLVM.\n",
        "\n",
        "<font color=\"orange\">***Caracter√≠sticas***</font>\n",
        "\n",
        "Numba oferece suporte para CUDA GPU programming, fornecendo um conjunto de primitivas para trabalhar com GPUs.\n",
        "\n",
        "<font color=\"orange\">***Pontos fortes e fracos***</font>\n",
        "\n",
        "üëç Pontos fortes:\n",
        "1. F√°cil de usar: Numba permite que voc√™ escreva fun√ß√µes CUDA em Python puro sem a necessidade de escrever qualquer c√≥digo CUDA C.\n",
        "2. Flex√≠vel: Numba suporta uma ampla variedade de tipos de dados e fun√ß√µes Python.\n",
        "3. Integrado: Numba se integra bem com o restante do ecossistema de ci√™ncia de dados Python, incluindo NumPy e pandas.\n",
        "\n",
        "üëé Pontos fracos:\n",
        "1. Desempenho: Embora o Numba possa alcan√ßar um desempenho pr√≥ximo ao do c√≥digo CUDA C para alguns tipos de c√°lculos, pode ser mais lento para outros.\n",
        "2. Menos controle: Como Numba abstrai muitos detalhes de baixo n√≠vel da programa√ß√£o CUDA, voc√™ tem menos controle sobre exatamente como seu c√≥digo √© executado na GPU."
      ],
      "metadata": {
        "id": "u3BBz0BfjQDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VsNEmfAj2i6",
        "outputId": "8543cb74-510e-4ed8-9b53-5063f79a441a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.10/dist-packages (from numba) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "@cuda.jit\n",
        "def add_kernel(x, y, out):\n",
        "    idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    \n",
        "    if idx < x.shape[0]:\n",
        "        out[idx] = x[idx] + y[idx]\n",
        "\n",
        "# Definindo 'a' e 'b'\n",
        "a = np.random.randn(50000).astype(np.float32)\n",
        "b = np.random.randn(50000).astype(np.float32)\n",
        "\n",
        "x = cuda.to_device(a)\n",
        "y = cuda.to_device(b)\n",
        "out = cuda.device_array_like(a)\n",
        "\n",
        "threads_per_block = 128\n",
        "\n",
        "# Calculando a quantidade de blocos dinamicamente\n",
        "blocks_per_grid = math.ceil(a.size / threads_per_block)\n",
        "\n",
        "add_kernel[blocks_per_grid, threads_per_block](x, y, out)\n",
        "\n",
        "# Copiando o resultado de volta para a mem√≥ria do host e imprimindo\n",
        "result = out.copy_to_host()\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik_IkSsrj2-h",
        "outputId": "8d4c6422-7be3-4c8e-fab8-7fabbf797135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.62347263  0.93233174  0.33516362 ... -0.983362   -1.0491279\n",
            "  0.79509676]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CuPy üé≤\n",
        "\n",
        "<font color=\"orange\">***O que √©***</font>\n",
        "\n",
        "CuPy √© uma implementa√ß√£o de NumPy na GPU.\n",
        "\n",
        "<font color=\"orange\">***Caracter√≠sticas***</font>\n",
        "\n",
        "Ele executa c√°lculos em uma GPU CUDA usando o CUDA nativo.\n",
        "\n",
        "<font color=\"orange\">***Pontos fortes e fracos***</font>\n",
        "\n",
        "üëç Pontos fortes:\n",
        "1. Interface semelhante ao NumPy: CuPy tem uma interface muito semelhante ao NumPy, tornando-o f√°cil de aprender para quem j√° est√° familiarizado com NumPy.\n",
        "2. Integrado: Como Numba, CuPy se integra bem com o restante do ecossistema de ci√™ncia de dados Python.\n",
        "\n",
        "üëé Pontos fracos:\n",
        "1. Menos controle: Como CuPy abstrai muitos detalhes da programa√ß√£o CUDA, voc√™ tem menos controle sobre exatamente como seu c√≥digo √© executado na GPU.\n",
        "2. Desempenho: Embora CuPy possa alcan√ßar um desempenho pr√≥ximo ao do c√≥digo CUDA C para opera√ß√µes de matriz, pode ser mais lento para outros tipos de c√°lculos."
      ],
      "metadata": {
        "id": "V4a4gCyytCMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16q1ln6wtKnT",
        "outputId": "9f9e0e4e-06fe-4ed5-e533-47ed532edf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cupy\n",
            "  Downloading cupy-12.0.0.tar.gz (2.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.27,>=1.20 in /usr/local/lib/python3.10/dist-packages (from cupy) (1.22.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy) (0.8.1)\n",
            "Building wheels for collected packages: cupy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Definindo 'a' e 'b'\n",
        "a = cp.random.randn(50000).astype(cp.float32)\n",
        "b = cp.random.randn(50000).astype(cp.float32)\n",
        "\n",
        "# Realizando a soma\n",
        "c = a + b\n",
        "\n",
        "print(c)"
      ],
      "metadata": {
        "id": "8syuvF-cu4Up",
        "outputId": "a810b0fd-c8be-4bd9-cb00-6e1b72d2bd29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.73264384  0.8214452   2.2367227  ...  0.2338723  -1.5182114\n",
            " -1.7386576 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyCUDA üöÄ\n",
        "\n",
        "<font color=\"orange\">***O que √©***</font>\n",
        "\n",
        "PyCUDA fornece acesso direto √† API CUDA a partir do Python. \n",
        "\n",
        "<font color=\"orange\">***Caracter√≠sticas***</font>\n",
        "\n",
        "Com PyCUDA, voc√™ pode escrever kernels C/C++ CUDA em Python e execut√°-los em GPUs CUDA.\n",
        "\n",
        "<font color=\"orange\">***Pontos fortes e fracos***</font>\n",
        "\n",
        "üëç Pontos fortes:\n",
        "1. Controle: PyCUDA d√° a voc√™ um controle muito granular sobre sua programa√ß√£o CUDA, permitindo otimiza√ß√µes de desempenho mais profundas.\n",
        "2. Flex√≠vel: PyCUDA permite que voc√™ escreva c√≥digo CUDA C completo e integre-o diretamente ao seu c√≥digo Python.\n",
        "\n",
        "üëé Pontos fracos:\n",
        "1. Dif√≠cil de usar: PyCUDA √© mais dif√≠cil de usar do que Numba ou CuPy porque requer conhecimento de CUDA C.\n",
        "2. Menos integrado: PyCUDA n√£o se integra t√£o facilmente com o restante do ecossistema de ci√™ncia de dados Python."
      ],
      "metadata": {
        "id": "V7p5IlGSr-UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq_Dupj8sPpi",
        "outputId": "3510a4e3-d8fb-4edc-8149-4872a126d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661989 sha256=a7350936421ee78304c6f432f0b66e78fdc420554d7f626b545a2d2a9881eaf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69866 sha256=4448affe5478779c14f6b2579b23c812e52abfe3a6f3da0b60607a5b4541c1c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/02/16/aa2498ad7aa723a149ff7539f1918509661c0ae9d975b44b6d\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void add_kernel(float *x, float *y, float *out, int size)\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    \n",
        "    if (idx < size)\n",
        "    {\n",
        "        out[idx] = x[idx] + y[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "add_kernel = mod.get_function(\"add_kernel\")\n",
        "\n",
        "# Definindo 'a' e 'b'\n",
        "a = np.random.randn(50000).astype(np.float32)\n",
        "b = np.random.randn(50000).astype(np.float32)\n",
        "\n",
        "x_gpu = cuda.mem_alloc(a.nbytes)\n",
        "y_gpu = cuda.mem_alloc(b.nbytes)\n",
        "out_gpu = cuda.mem_alloc(a.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(x_gpu, a)\n",
        "cuda.memcpy_htod(y_gpu, b)\n",
        "\n",
        "threads_per_block = 128\n",
        "\n",
        "# Calculando a quantidade de blocos dinamicamente\n",
        "blocks_per_grid = math.ceil(a.size / threads_per_block)\n",
        "\n",
        "add_kernel(x_gpu, y_gpu, out_gpu, np.int32(a.size), block=(threads_per_block,1,1), grid=(blocks_per_grid,1))\n",
        "\n",
        "out = np.empty_like(a)\n",
        "cuda.memcpy_dtoh(out, out_gpu)\n",
        "\n",
        "print(out)\n"
      ],
      "metadata": {
        "id": "-atvCrU-t_g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CUDA Python üöÄüêç\n",
        "\n",
        "<font color=\"orange\">***O que √©?***</font>\n",
        "\n",
        "O objetivo do CUDA Python √© unificar o ecossistema Python com um √∫nico conjunto de interfaces que fornecem total cobertura e acesso √†s APIs de host CUDA do Python.\n",
        "\n",
        "<font color=\"orange\">***Caracter√≠sticas***</font>\n",
        "\n",
        "- Bindings Cython e wrappers Python para as APIs de driver e runtime CUDA.\n",
        "- CUDA Python tamb√©m √© compat√≠vel com NVIDIA Nsight Compute. \n",
        "- Aparenta ter um bom desempenho quando comparado com C++.\n",
        "\n",
        "<font color=\"orange\">***Pontos fortes e fracos***</font>\n",
        "\n",
        "üëç Pontos fortes:\n",
        "- Permite a r√°pida itera√ß√£o de desenvolvimento com Python.\n",
        "- Oferece a velocidade de uma linguagem compilada direcionada tanto para CPUs quanto para GPUs NVIDIA.\n",
        "- Possibilita a interoperabilidade entre diferentes bibliotecas aceleradas.\n",
        "\n",
        "<center>\n",
        "<figure>\n",
        "    <img src=\"https://imgur.com/SjGOLPH.png\" alt=\"smit\" width=400 heigh=100>\n",
        "        <figcaption>Fonte: <a href=\"https://nvidia.github.io/cuda-python/overview.html\">https://nvidia.github.io/cuda-python/overview.html</a>\n",
        "</figcaption>\n",
        "</figure>\n",
        "</center>\n",
        "\n",
        "üëé Pontos fracos:\n",
        "- O √∫nico ponto fraco √© que ele requer alguma compreens√£o de CUDA C++, o que pode ser um desafio para alguns desenvolvedores Python.\n",
        "- Est√° em desenvolvimento entƒÅo pode ser que nƒÅo encontre suporte para algumas bibliotecas."
      ],
      "metadata": {
        "id": "bAeWwUIE3pj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cuda-python"
      ],
      "metadata": {
        "id": "d_ntVszA9g6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-python.git"
      ],
      "metadata": {
        "id": "3Ql8Kl1bK9Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/cuda-python')\n",
        "sys.path.append('/content/cuda-python/examples')\n",
        "sys.path.append('/content/cuda-python/examples/common')"
      ],
      "metadata": {
        "id": "alr2V6IWXcAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/cuda-python/examples"
      ],
      "metadata": {
        "id": "yUYcUtqbXt0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2021-2023 NVIDIA Corporation.  All rights reserved.\n",
        "#\n",
        "# Please refer to the NVIDIA end user license agreement (EULA) associated\n",
        "# with this source code for terms and conditions that govern your use of\n",
        "# this software. Any use, reproduction, disclosure, or distribution of\n",
        "# this software and related documentation outside the terms of the EULA\n",
        "# is strictly prohibited.\n",
        "# https://github.com/NVIDIA/cuda-python\n",
        "\n",
        "import ctypes\n",
        "import math\n",
        "import numpy as np\n",
        "from cuda import cuda\n",
        "from common import common\n",
        "from common import checkCudaErrors, findCudaDeviceDRV\n",
        "\n",
        "vectorAddDrv = '''\\\n",
        "/* Vector addition: C = A + B.\n",
        " *\n",
        " * This sample is a very basic sample that implements element by element\n",
        " * vector addition. It is the same as the sample illustrating Chapter 3\n",
        " * of the programming guide with some additions like error checking.\n",
        " *\n",
        " */\n",
        "\n",
        "// Device code\n",
        "extern \"C\" __global__ void VecAdd_kernel(const float *A, const float *B, float *C, int N)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < N)\n",
        "        C[i] = A[i] + B[i];\n",
        "}\n",
        "'''\n",
        "\n",
        "def main():\n",
        "    print(\"Vector Addition (Driver API)\")\n",
        "    N = 50000\n",
        "    devID = 0\n",
        "    size = N * np.dtype(np.float32).itemsize\n",
        "\n",
        "    # Initialize\n",
        "    checkCudaErrors(cuda.cuInit(0));\n",
        "\n",
        "    cuDevice = findCudaDeviceDRV()\n",
        "    # Create context\n",
        "    cuContext = checkCudaErrors(cuda.cuCtxCreate(0, cuDevice))\n",
        "\n",
        "    uvaSupported = checkCudaErrors(cuda.cuDeviceGetAttribute(cuda.CUdevice_attribute.CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING, cuDevice))\n",
        "    if not uvaSupported:\n",
        "        print(\"Accessing pageable memory directly requires UVA\")\n",
        "        return\n",
        "\n",
        "    kernelHelper = common.KernelHelper(vectorAddDrv, int(cuDevice))\n",
        "    _VecAdd_kernel = kernelHelper.getFunction(b'VecAdd_kernel')\n",
        "\n",
        "    # Allocate input vectors h_A and h_B in host memory\n",
        "    h_A = np.random.rand(size).astype(dtype=np.float32)\n",
        "    h_B = np.random.rand(size).astype(dtype=np.float32)\n",
        "    h_C = np.random.rand(size).astype(dtype=np.float32)\n",
        "\n",
        "    # Allocate vectors in device memory\n",
        "    d_A = checkCudaErrors(cuda.cuMemAlloc(size))\n",
        "    d_B = checkCudaErrors(cuda.cuMemAlloc(size))\n",
        "    d_C = checkCudaErrors(cuda.cuMemAlloc(size))\n",
        "\n",
        "    # Copy vectors from host memory to device memory\n",
        "    checkCudaErrors(cuda.cuMemcpyHtoD(d_A, h_A, size))\n",
        "    checkCudaErrors(cuda.cuMemcpyHtoD(d_B, h_B, size))\n",
        "\n",
        "    if True:\n",
        "        # Grid/Block configuration\n",
        "        threadsPerBlock = 256\n",
        "        blocksPerGrid   = (N + threadsPerBlock - 1) / threadsPerBlock\n",
        "\n",
        "        kernelArgs = ((d_A, d_B, d_C, N),\n",
        "                      (None, None, None, ctypes.c_int))\n",
        "\n",
        "        # Launch the CUDA kernel\n",
        "        checkCudaErrors(cuda.cuLaunchKernel(_VecAdd_kernel,\n",
        "                                            blocksPerGrid, 1, 1,\n",
        "                                            threadsPerBlock, 1, 1,\n",
        "                                            0, 0,\n",
        "                                            kernelArgs, 0))\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    # Copy result from device memory to host memory\n",
        "    # h_C contains the result in host memory\n",
        "    checkCudaErrors(cuda.cuMemcpyDtoH(h_C, d_C, size))\n",
        "\n",
        "    for i in range(N):\n",
        "        sum_all = h_A[i] + h_B[i]\n",
        "        if math.fabs(h_C[i] - sum_all) > 1e-7:\n",
        "            break\n",
        "\n",
        "    # Free device memory\n",
        "    checkCudaErrors(cuda.cuMemFree(d_A))\n",
        "    checkCudaErrors(cuda.cuMemFree(d_B))\n",
        "    checkCudaErrors(cuda.cuMemFree(d_C))\n",
        "\n",
        "    checkCudaErrors(cuda.cuCtxDestroy(cuContext))\n",
        "    print(\"{}\".format(\"Result = PASS\" if i+1 == N else \"Result = FAIL\"))\n",
        "    if i+1 != N:\n",
        "        sys.exit(-1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "E9Pv37IV9hqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèÅ Conclus√£o\n",
        "\n",
        "- üí° Vale ressaltar que **Numba**, **CuPy**, **CUDA Python** e **PyCUDA** n√£o s√£o apenas abordagens, mas **ferramentas** para explorar a acelera√ß√£o **CUDA** diretamente do **Python**.\n",
        "\n",
        "- ü§ù A _interoperabilidade_ entre essas ferramentas abre um vasto leque de possibilidades e solu√ß√µes, tornando a programa√ß√£o com acelera√ß√£o **CUDA** mais **acess√≠vel** e **vers√°til** do que jamais imaginamos.\n",
        "\n",
        "- üõ† Al√©m disso, dominar os conceitos de C/C++ CUDA √© crucial para ter solu√ß√µes com um controle maior. Essas solu√ß√µes podem ser incorporadas ao Python quando necess√°rio, ampliando ainda mais as  possibilidades!"
      ],
      "metadata": {
        "id": "IycwdIYTeajL"
      }
    }
  ]
}